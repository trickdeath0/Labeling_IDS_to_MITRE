{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "bjeNca00bwQD",
        "-D9rfL2roNR9",
        "nz_5UVOypq2-",
        "D4PEMeOAKNiN",
        "T0dV1xXnpqrv",
        "9PDyuWeDpqkn",
        "7aOvvGzApqUQ",
        "Au3iaHvfg2_g",
        "qhl0OOPpdQ4Z",
        "N4aLDGzriV55"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Install\n",
        "\n",
        "SDK: https://github.com/anthropics/anthropic-sdk-python"
      ],
      "metadata": {
        "id": "TeA9IRSmjX3M"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ow6ph5mIi6Q4",
        "outputId": "5a2bb9a1-2f09-4107-a2e2-b5b9bf9bb0fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting anthropic\n",
            "  Downloading anthropic-0.28.0-py3-none-any.whl (862 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m862.7/862.7 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from anthropic) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from anthropic) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from anthropic)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jiter<1,>=0.4.0 (from anthropic)\n",
            "  Downloading jiter-0.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (327 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m327.6/327.6 kB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from anthropic) (2.7.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from anthropic) (1.3.1)\n",
            "Requirement already satisfied: tokenizers>=0.13.0 in /usr/local/lib/python3.10/dist-packages (from anthropic) (0.19.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from anthropic) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->anthropic) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->anthropic) (1.2.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->anthropic) (2024.6.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->anthropic)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->anthropic)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->anthropic) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->anthropic) (2.18.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers>=0.13.0->anthropic) (0.23.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (3.14.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (2023.6.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (6.0.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (4.66.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (2.0.7)\n",
            "Installing collected packages: jiter, h11, httpcore, httpx, anthropic\n",
            "Successfully installed anthropic-0.28.0 h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 jiter-0.4.2\n"
          ]
        }
      ],
      "source": [
        "!pip install anthropic\n",
        "\n",
        "import os\n",
        "import json\n",
        "import pandas as pd\n",
        "import time\n",
        "import re\n",
        "import csv"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# This is formatted as code\n",
        "\n",
        "\n",
        "### Import packages"
      ],
      "metadata": {
        "id": "zn-Yf90tjrYE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pathlib\n",
        "import textwrap\n",
        "\n",
        "\n",
        "from IPython.display import display\n",
        "from IPython.display import Markdown\n",
        "\n",
        "\n",
        "def to_markdown(text):\n",
        "  text = text.replace('‚Ä¢', '  *')\n",
        "  return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))\n",
        "\n",
        "  # Used to securely store your API key\n",
        "from google.colab import userdata"
      ],
      "metadata": {
        "id": "UXCqrterjsNL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Setup your API key\n",
        "\n",
        "Before you can use the Cluade API, you must first obtain an API key. If you don't already have one, create a key with one click in Google AI Studio.\n",
        "\n",
        "<a class=\"button button-primary\" href=\"https://console.anthropic.com/settings/keys\" target=\"_blank\" rel=\"noopener noreferrer\">Get an API key</a>\n",
        "\n",
        "\n",
        "In Colab, add the key to the secrets manager under the \"üîë\" in the left panel. Give it the name `CLUADE_API_KEY`.\n",
        "\n",
        "Once you have the API key, pass it to the SDK. You can do this in two ways:\n",
        "\n",
        "* Put the key in the `CLUADE_API_KEY` environment variable (the SDK will automatically pick it up from there).\n"
      ],
      "metadata": {
        "id": "--UHHBFrj38s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from anthropic import Anthropic\n",
        "\n",
        "client = Anthropic(\n",
        "    # This is the default and can be omitted\n",
        "    # Or use `os.getenv('finalproject-secret-key')` to fetch an environment variable.\n",
        "    #CLUADE_API_KEY=userdata.get('finalproject-secret-key')\n",
        "    api_key=userdata.get(\"ANTHROPIC_API_KEY\"),\n",
        ")\n"
      ],
      "metadata": {
        "id": "b1w5Tp-VkKtj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Demo test for us"
      ],
      "metadata": {
        "id": "kCOCeXotojsW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "snort_rule = '''alert tcp $HOME_NET [21,25,443,465,636,992,993,995,2484] -> $EXTERNAL_NET any ( msg:\"SERVER-OTHER OpenSSL TLSv1.1 large heartbeat response - possible ssl heartbleed attempt\"; flow:to_client,established; content:\"|16 03 02|\"; byte_jump:2,0,relative; content:\"|18 03 02|\",within 3,fast_pattern; byte_test:2,>,128,0,relative; metadata:policy max-detect-ips drop,policy security-ips drop,ruleset community; service:ssl; reference:cve,2014-0160; classtype:attempted-recon; sid:30781; rev:5; )'''\n",
        "\n",
        "message = client.messages.create(\n",
        "    max_tokens=1024,\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": f\"\"\"\n",
        "                          I'm going to give you a Snort rule. Read the Snort rule carefully, because I'm going to given you a task about it. Here is the Snort rule: <snort_rule>{snort_rule}</snort_rule>\n",
        "\n",
        "                          First, find the techniques from MITRE ATT&CK that are most relevant to the Snort rule.\n",
        "\n",
        "                          Then, answer the task, for each technique include the following information as JSON in this order: 'Sid', 'Technique ID', 'Technique Name', 'Quotes', 'Explanation'.\n",
        "\n",
        "                          Note: The value of the citation field should contain quotation marks from the data sets relevant to the mapped technique are the main reason you chose this technique to be correct. The value of the explanation should be your explanation of why you decided to give the technique and how it relates to the rule. The technique ID should be the official MITRE technique ID.\n",
        "\n",
        "                          Thus, the format of your overall response should look like what's shown between the <examples></examples> tags. Make sure to follow the formatting and spacing exactly.\n",
        "\n",
        "\n",
        "                          <examples>\n",
        "                          [\n",
        "                            \"sid\": \"2274\",\n",
        "                            \"Technique ID\": \"T1110\",\n",
        "                            \"Technique name\": \"Brute Force\",\n",
        "                            \"Quotes\": [\n",
        "                              \"\\\"PROTOCOL-POP login brute force attempt\\\"\",\n",
        "                              \"track by_dst,count 30,seconds 30\"\n",
        "                            ],\n",
        "                            \"Explanation\": \"The rule is looking for excessive \\\"USER\\\" commands within a short period of time, which are common indicators of brute-force attacks targeting the POP3 service.\"\n",
        "                          ]\n",
        "                          </examples>\n",
        "\n",
        "                          Do not include anything besides write the JSON.\n",
        "                          \"\"\",\n",
        "        }\n",
        "    ],\n",
        "    model=\"claude-2.1\",\n",
        "    temperature=0,\n",
        ")\n",
        "\n",
        "\n",
        "#print(message.content) # list"
      ],
      "metadata": {
        "id": "p3L4kX_BoI1u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = str(message.content)\n",
        "#text = str(message.content).split(\"\\\\n\\\\n\")[1].split(\"', type\")[0]\n",
        "print(type(text))\n",
        "print(text)\n",
        "\n",
        "t_numbers = re.findall(r'[\\'\\\"](T\\d+(?:\\.\\d+)?)', text)\n",
        "\n",
        "print(t_numbers)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qE39uDRoqlos",
        "outputId": "d4aff1f6-8787-4a8d-874f-2b95ed0e5073"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'str'>\n",
            "[ContentBlock(text='{\\n    \"Sid\": \"30781\",\\n    \"Technique ID\": \"T1529\",\\n    \"Technique Name\": \"System Services Discovery\",\\n    \"Quotes\": \"\\\\\"This rule detects attackers attempting to exploit the Heartbleed vulnerability in OpenSSL to read sensitive information from the server\\'s memory.\\\\\"\",\\n    \"Explanation\": \"The rule is looking for signs of attackers trying to exploit the Heartbleed vulnerability, which allows reading sensitive data from memory. This aligns with the System Services Discovery technique in MITRE ATT&CK, which involves gathering information about services running on remote systems. The attempt to exploit Heartbleed to gather data is a form of system services discovery.\"\\n}', type='text')]\n",
            "['T1529']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data:\n",
        "Our data will be taken from 162 snort rules that have already been manually labeled to techniques from MITRE ATT&CK."
      ],
      "metadata": {
        "id": "AasGoYO3oARv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/trickdeath0/Labeling_IDS_to_MITRE.git"
      ],
      "metadata": {
        "id": "6HZLffHfk_ee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64dafa2a-ba42-4b2f-ab79-999604cb4c60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Labeling_IDS_to_MITRE'...\n",
            "remote: Enumerating objects: 413, done.\u001b[K\n",
            "remote: Counting objects: 100% (413/413), done.\u001b[K\n",
            "remote: Compressing objects: 100% (287/287), done.\u001b[K\n",
            "remote: Total 413 (delta 216), reused 307 (delta 111), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (413/413), 9.19 MiB | 10.44 MiB/s, done.\n",
            "Resolving deltas: 100% (216/216), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# data = pd.read_csv('/content/Labeling_IDS_to_MITRE/ground_truth.csv') # Nir experiment\n",
        "data = pd.read_csv('/content/Labeling_IDS_to_MITRE/Semester_B/01 stratification/test_data_fix.csv') # Our experiment\n",
        "print(data.head())\n",
        "rules_list = data['Rule']\n",
        "true_labels = data['technique ids']\n",
        "\n",
        "#print(data['Sid'][0+41])\n",
        "print(f\"\\n{len(data)=}\")"
      ],
      "metadata": {
        "id": "iZaI6p6-oIiO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2568748-ffef-44af-ea55-46658740f9c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Sid                                  URL       technique ids  \\\n",
            "0  50094  https://snort.org/rule_docs/1-50094           ['T1187']   \n",
            "1  38563  https://snort.org/rule_docs/1-38563           ['T1056']   \n",
            "2    976    https://snort.org/rule_docs/1-976           ['T1204']   \n",
            "3   1129   https://snort.org/rule_docs/1-1129           ['T1218']   \n",
            "4  27967  https://snort.org/rule_docs/1-27967  ['T1505', 'T1219']   \n",
            "\n",
            "                                                Rule  \n",
            "0  alert tcp any $HTTP_PORTS -> any any ( msg:\"IN...  \n",
            "1  alert tcp $EXTERNAL_NET $HTTP_PORTS -> $HOME_N...  \n",
            "2  alert tcp $EXTERNAL_NET any -> $HTTP_SERVERS $...  \n",
            "3  alert tcp $EXTERNAL_NET any -> $HTTP_SERVERS $...  \n",
            "4  alert tcp $EXTERNAL_NET any -> $HOME_NET $HTTP...  \n",
            "\n",
            "len(data)=300\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_response(text):\n",
        "    text = text.data.replace(\">\", \"\").strip()  # Remove leading \">\", whitespace\n",
        "    try:\n",
        "      text = text.replace(\"```json\", \"\")\n",
        "      text = text.replace(\"```\", \"\")\n",
        "    except:\n",
        "      pass\n",
        "    return text\n"
      ],
      "metadata": {
        "id": "z6Lqlzg1oMiX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Zero Shot (ZS):**\n",
        "At this stage, the LLMs will receive a prompt that does not include the list of techniques from MITRE ATT&CK in order to examine the results of the models based on prior knowledge that has been trained. According to our request, the LLMs will classify the techniques according to the content of the rule."
      ],
      "metadata": {
        "id": "bjeNca00bwQD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def ZS(snort_rule):\n",
        "\n",
        "  prompt = f\"\"\"Rule: {snort_rule}\n",
        "  Return a MITRE technique ID (with quotation marks) that related to the rule\"\"\"\n",
        "\n",
        "\n",
        "  message = client.messages.create(\n",
        "      max_tokens=1024,\n",
        "      messages=[\n",
        "          {\n",
        "              \"role\": \"user\",\n",
        "              \"content\": prompt,\n",
        "          }\n",
        "      ],\n",
        "      model=\"claude-3-sonnet-20240229\",\n",
        "      temperature=0,\n",
        "  )\n",
        "\n",
        "  return message"
      ],
      "metadata": {
        "id": "Q4ej4JMxbw3S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = '''\n",
        "\"alert udp $HOME_NET any -> $EXTERNAL_NET 15165 ( msg:\"\"MALWARE-OTHER Keylogger stealthwatcher 2000 runtime detection - agent up notification\"\"; content:\"\"|00 00 00 00 0A 02 08 A6|\"\",depth 8; content:\"\"|02 00 00|v\"\",distance 0; classtype:successful-recon-limited; sid:6386; rev:8; )\"\n",
        "'''\n",
        "\n",
        "print(ZS(a))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bedm8DZPcIAi",
        "outputId": "f047c33c-a4d8-4c18-9aee-63c0b2613121"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Message(id='msg_01F71A7QyT4ZLYF1PoydRxio', content=[TextBlock(text='Based on the rule description \"MALWARE-OTHER Keylogger stealthwatcher 2000 runtime detection - agent up notification\", the relevant MITRE technique ID is:\\n\\n\"T1556.002\"\\n\\nThis technique ID corresponds to \"Credential Access: Credentials from Web Browsers\" in the MITRE ATT&CK framework, which includes keylogging as a method for capturing credentials from web browsers.', type='text')], model='claude-3-sonnet-20240229', role='assistant', stop_reason='end_turn', stop_sequence=None, type='message', usage=Usage(input_tokens=143, output_tokens=95))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Prompting without techniques guide and without example (WTGWE):**\n",
        "At this stage, the LLMs will receive a prompt that does not include the list of techniques from MITRE ATT&CK in order to examine the results of the models based on prior knowledge that has been trained. According to our request, the LLMs will classify the techniques according to the content of the rule.\n"
      ],
      "metadata": {
        "id": "-D9rfL2roNR9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Prompt1**:\n",
        "\n",
        "      prompt = f\"\"\"You are an information security expert. Your task is to label IDS rules for MITRE ATT&CK techniques based on your cybersecurity knowledge. For the task, you are going to get a single Snort IDS rule and you will need to return the most relevant techniques from MITRE ATT&CK that are related to the rule.\n",
        "      Try to search based on keywords and based on the knowledge you have. For each technique include the following information as JSON in this order: 'Sid', 'Technique ID', 'Technique Name', 'Quotes', 'Explanation'.\n",
        "      Note: The value of the citation field should contain quotation marks from the data sets relevant to the mapped technique are the main reason you chose this technique to be correct. The value of the explanation should be your explanation of why you decided to give the technique and how it relates to the rule. The technique ID should be the official MITRE technique ID.\n",
        "      Please don't write anything but the JSON. Rule: {snort_rule}\"\"\"\n",
        "\n",
        "\n",
        "**prompt2**:\n",
        "\n",
        "      prompt2 = f\"\"\"I'm going to give you a Snort rule. Read the Snort rule carefully, because I'm going to given you a task about it. Here is the Snort rule: <snort_rule>{snort_rule}</snort_rule>\n",
        "\n",
        "      First, find the techniques from MITRE ATT&CK that are most relevant to the Snort rule.\n",
        "\n",
        "      Then, answer the task, for each technique include the following information as JSON in this order: 'Sid', 'Technique ID', 'Technique Name', 'Quotes', 'Explanation'.\n",
        "\n",
        "      Note: The value of the citation field should contain quotation marks from the data sets relevant to the mapped technique are the main reason you chose this technique to be correct. The value of the explanation should be your explanation of why you decided to give the technique and how it relates to the rule. The technique ID should be the official MITRE technique ID.\n",
        "\n",
        "      Thus, the format of your overall response should look like what's shown between the <examples></examples> tags. Make sure to follow the formatting and spacing exactly.\n",
        "\n",
        "\n",
        "      <examples>\n",
        "        [\n",
        "          \"sid\": \"2274\",\n",
        "          \"Technique ID\": \"T1110\",\n",
        "          \"Technique name\": \"Brute Force\",\n",
        "          \"Quotes\": [\n",
        "            \"\\\"PROTOCOL-POP login brute force attempt\\\"\",\n",
        "            \"track by_dst,count 30,seconds 30\"\n",
        "          ],\n",
        "          \"Explanation\": \"The rule is looking for excessive \\\"USER\\\" commands within a short period of time, which are common indicators of brute-force attacks targeting the POP3 service.\"\n",
        "        ]\n",
        "        </examples>\n",
        "\n",
        "        Do not include anything besides write the JSON.\n",
        "        \"\"\"\n",
        "\n",
        "\n",
        "**prompt3**:\n",
        "\n",
        "        prompt3 = f\"\"\"You work in a company that deals with information security, your role in the company is to label techniques from MITRE ATT&CK to the rules of IDS systems. The labeling between a rule and a technique indicates that the attacker operated with a technique that you found to be suitable for the rule that alerted the IDS system. Now we will test your knowledge labeling IDS rules for MITRE ATT&CK techniques. For your task, you're going to have a single Snort IDS rule and you'll need to label the most relevant techniques from MITRE ATT&CK associated with the rule. From the rule you receive, your labeling should be based on your knowledge and the information found within the 'msg' in the rule received. For each technique you call the rule, include the following information as JSON format in this order: 'Sid', 'Technique ID', 'Technique Name', 'Quotes', 'Explanation'.  Note: The value of the 'Quotes' field should contain quotation marks from the data sets relevant to the mapped technique. The value of the 'Explanation' should be your explanation of why you decided to give the technique and how it relates to the rule. The 'Technique ID' should be the official MITRE technique ID.\n",
        "        Please don't write anything but the JSON. Rule: {snort_rule}\"\"\")\n",
        "\n",
        "\n",
        "**prompt4**\n",
        "\n",
        "        prompt4 = f'''You are going to receive a Snort rule and your task is to find as many MITRE ATT&CK techniques as possible that are associated with the rule. Note: You should categorize the techniques to 1 or 2. Technique of type 1 is a technique that you can associate with the rule directly based on the rule. Technique of type 2 is a technique that can be associated with the rule indirectly, based on your knowledge and understanding. The categorization value should be the value 1 or 2, based on the explanation given above. The quotes field value should contain quotes from the rules data that are relevant to the technique mapped and they are the main reason you believe the mapping to this technique is correct. The explanation‚Äôs value should be your explanation for why you decided to give the technique and how it is associated with the rule. The technique id should be the official MITRE technique id. For each technique include the following information as JSON: sid, Technique id, Technique name, Categorization, Quotes, Explanation. After each rule I will provide you with, answer according to the provided format. Please do not write anything else but the JSON. Rule: {snort_rule}''')\n",
        "\n",
        "\n",
        "**prompt5 fix:**\n",
        "\n",
        "        prompt5 = f\"\"\"You are an information security expert. Your task is to label IDS rules for MITER ATT&CK techniques based on your cybersecurity knowledge. For the task, you are going to get a single Snort IDS rule and you will need to return no more than 2 most relevant techniques from MITER ATT&CK that are related to the rule.\n",
        "        Try to search based on keywords and based on the knowledge you have. For each technique include the following information as JSON in this order: 'Sid', 'Technique ID', 'Technique Name', 'Quotes', 'Explanation'.\n",
        "        Note: The value of the citation field should contain quotation marks from the data sets relevant to the mapped technique are the main reason you chose this technique to be correct. The value of the explanation should be your explanation of why you decided to give the technique and how it relates to the rule. The technique ID should be the official MITER technique ID.\n",
        "        Please don't write anything but the JSON. Rule: {snort_rule}\"\"\""
      ],
      "metadata": {
        "id": "0-HP8vQIijhJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def WTGWE(snort_rule):\n",
        "\n",
        "  # prompt = f\"\"\"You are an information security expert. Your task is to label IDS rules for MITRE ATT&CK techniques based on your cybersecurity knowledge. For the task, you are going to get a single Snort IDS rule and you will need to return the most relevant techniques from MITRE ATT&CK that are related to the rule.\n",
        "  #             Try to search based on keywords and based on the knowledge you have. For each technique include the following information as JSON in this order: 'Sid', 'Technique ID', 'Technique Name', 'Quotes', 'Explanation'.\n",
        "  #             Note: The value of the citation field should contain quotation marks from the data sets relevant to the mapped technique are the main reason you chose this technique to be correct. The value of the explanation should be your explanation of why you decided to give the technique and how it relates to the rule. The technique ID should be the official MITRE technique ID.\n",
        "  #             Please don't write anything but the JSON. Rule: {snort_rule}\"\"\"\n",
        "\n",
        "  prompt = f\"\"\"I'm going to give you a Snort rule. Read the Snort rule carefully, because I'm going to given you a task about it. Here is the Snort rule: <snort_rule>{snort_rule}</snort_rule>\n",
        "\n",
        "  First, your task is to return no more than 2 most relevant techniques from MITER ATT&CK that are related to the Snort rule.\n",
        "\n",
        "  Then, answer the task, for each technique include the following information as JSON in this order: 'Sid', 'Technique ID', 'Technique Name', 'Quotes', 'Explanation'.\n",
        "\n",
        "  Note: The value of the citation field should contain quotation marks from the data sets relevant to the mapped technique are the main reason you chose this technique to be correct. The value of the explanation should be your explanation of why you decided to give the technique and how it relates to the rule. The technique ID should be the official MITRE technique ID.\n",
        "\n",
        "\n",
        "  <examples>\n",
        "    [\n",
        "      \"sid\": \"\",\n",
        "      \"Technique ID\": \"\",\n",
        "      \"Technique name\": \"\",\n",
        "      \"Quotes\": [\"\"],\n",
        "      \"Explanation\": \"\"\n",
        "    ]\n",
        "    </examples>\n",
        "\n",
        "    Do not include anything besides write the JSON.\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "  message = client.messages.create(\n",
        "      max_tokens=1024,\n",
        "      messages=[\n",
        "          {\n",
        "              \"role\": \"user\",\n",
        "              \"content\": prompt,\n",
        "          }\n",
        "      ],\n",
        "      model=\"claude-3-sonnet-20240229\",\n",
        "      temperature=0,\n",
        "  )\n",
        "\n",
        "  return message"
      ],
      "metadata": {
        "id": "MQqU79vkoUym"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Prompting without techniques guide and with 1 example (WTG1E):**\n",
        "At this stage, the LLMs will receive a prompt that does not include the list of techniques from MITRE ATT&CK in order to examine the results of the models based on prior knowledge that has been trained. According to our request, the LLMs will classify the techniques according to the content of the rule.\n",
        "\n",
        "In addition, the prompt has one example (one shot)\n"
      ],
      "metadata": {
        "id": "nz_5UVOypq2-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def WTG1E(snort_rule):\n",
        "\n",
        "  # prompt = f\"\"\"Q: You are an information security expert. Your task is to label IDS rules for MITRE ATT&CK techniques based on your cybersecurity knowledge. For the task, you are going to get a single Snort IDS rule and you will need to return the most relevant techniques from MITRE ATT&CK that are related to the rule.\n",
        "  #   Try to search based on keywords and based on the knowledge you have. For each technique include the following information as JSON in this order: 'Sid', 'Technique ID', 'Technique Name', 'Quotes', 'Explanation'.\n",
        "  #   Note: The value of the citation field should contain quotation marks from the data sets relevant to the mapped technique are the main reason you chose this technique to be correct. The value of the explanation should be your explanation of why you decided to give the technique and how it relates to the rule. The technique ID should be the official MITRE technique ID.\n",
        "  #   Please don't write anything but the JSON. Rule: \"alert tcp $EXTERNAL_NET $HTTP_PORTS -> $HOME_NET any ( msg:\"\"MALWARE-CNC Win.Trojan.GateKeylogger fake 404 response\"\"; flow:to_client,established; http_stat_code; content:\"\"200\"\"; http_stat_msg; content:\"\"OK\"\"; pkt_data; content:\"\">404 Not Found<\"\",fast_pattern,nocase; content:\"\" requested URL / was not found \"\"; metadata:impact_flag red,ruleset community; service:http; T1056; classtype:trojan-activity; sid:38563; rev:4; )\"\n",
        "  #   A: [\n",
        "  #       \"sid\": \"38563\",\n",
        "  #       \"Technique ID\": \"T1056\",\n",
        "  #       \"Technique name\": \"Input Capture\",\n",
        "  #       \"Quotes\": \"\\\"Input Capture techniques involve intercepting and capturing user input data, such as keystrokes, to obtain sensitive information. The rule indicates the presence of a Trojan (GateKeylogger) that mimics a '404 Not Found' error to disguise its communication with a command and control server, which is a common method used by keyloggers to stealthily capture input data.\\\"\",\n",
        "  #       \"Explanation\": \"This event is generated when activity relating to malware is detected.\"\n",
        "  #   ]\n",
        "\n",
        "  #   Q: You are an information security expert. Your task is to label IDS rules for MITRE ATT&CK techniques based on your cybersecurity knowledge. For the task, you are going to get a single Snort IDS rule and you will need to return the most relevant techniques from MITRE ATT&CK that are related to the rule.\n",
        "  #   Try to search based on keywords and based on the knowledge you have. For each technique include the following information as JSON in this order: 'Sid', 'Technique ID', 'Technique Name', 'Quotes', 'Explanation'.\n",
        "  #   Note: The value of the citation field should contain quotation marks from the data sets relevant to the mapped technique are the main reason you chose this technique to be correct. The value of the explanation should be your explanation of why you decided to give the technique and how it relates to the rule. The technique ID should be the official MITRE technique ID.\n",
        "  #   Please don't write anything but the JSON. Rule: {snort_rule}\n",
        "  #   A: \"\"\"\n",
        "\n",
        "\n",
        "\n",
        "  prompt_with_example = f\"\"\"Q: I'm going to give you a Snort rule. Read the Snort rule carefully, because I'm going to given you a task about it. Here is the Snort rule: <snort_rule>\"alert tcp $EXTERNAL_NET $HTTP_PORTS -> $HOME_NET any ( msg:\"\"MALWARE-CNC Win.Trojan.GateKeylogger fake 404 response\"\"; flow:to_client,established; http_stat_code; content:\"\"200\"\"; http_stat_msg; content:\"\"OK\"\"; pkt_data; content:\"\">404 Not Found<\"\",fast_pattern,nocase; content:\"\" requested URL / was not found \"\"; metadata:impact_flag red,ruleset community; service:http; T1056; classtype:trojan-activity; sid:38563; rev:4; )\"</snort_rule>\n",
        "\n",
        "  First, your task is to return no more than 2 most relevant techniques from MITER ATT&CK that are related to the Snort rule.\n",
        "\n",
        "  Then, answer the task, for each technique include the following information as JSON in this order: 'Sid', 'Technique ID', 'Technique Name', 'Quotes', 'Explanation'.\n",
        "\n",
        "  Note: The value of the citation field should contain quotation marks from the data sets relevant to the mapped technique are the main reason you chose this technique to be correct. The value of the explanation should be your explanation of why you decided to give the technique and how it relates to the rule. The technique ID should be the official MITRE technique ID.\n",
        "\n",
        "\n",
        "  <examples>\n",
        "    [\n",
        "      \"sid\": \"\",\n",
        "      \"Technique ID\": \"\",\n",
        "      \"Technique name\": \"\",\n",
        "      \"Quotes\": [\"\"],\n",
        "      \"Explanation\": \"\"\n",
        "    ]\n",
        "    </examples>\n",
        "\n",
        "    Do not include anything besides write the JSON.\n",
        "    \"\"\"\n",
        "\n",
        "  answer_we_expect = f\"\"\"\n",
        "    [\n",
        "        \"sid\": \"38563\",\n",
        "        \"Technique ID\": \"T1056\",\n",
        "        \"Technique name\": \"Input Capture\",\n",
        "        \"Quotes\": \"\\\"Input Capture techniques involve intercepting and capturing user input data, such as keystrokes, to obtain sensitive information. The rule indicates the presence of a Trojan (GateKeylogger) that mimics a '404 Not Found' error to disguise its communication with a command and control server, which is a common method used by keyloggers to stealthily capture input data.\\\"\",\n",
        "        \"Explanation\": \"This event is generated when activity relating to malware is detected.\"\n",
        "    ]\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  prompt = f\"\"\"\n",
        "  I'm going to give you a Snort rule. Read the Snort rule carefully, because I'm going to given you a task about it. Here is the Snort rule: <snort_rule>{snort_rule}</snort_rule>\n",
        "\n",
        "  First, your task is to return no more than 2 most relevant techniques from MITER ATT&CK that are related to the Snort rule.\n",
        "\n",
        "  Then, answer the task, for each technique include the following information as JSON in this order: 'Sid', 'Technique ID', 'Technique Name', 'Quotes', 'Explanation'.\n",
        "\n",
        "  Note: The value of the citation field should contain quotation marks from the data sets relevant to the mapped technique are the main reason you chose this technique to be correct. The value of the explanation should be your explanation of why you decided to give the technique and how it relates to the rule. The technique ID should be the official MITRE technique ID.\n",
        "\n",
        "\n",
        "  <examples>\n",
        "    [\n",
        "      \"sid\": \"\",\n",
        "      \"Technique ID\": \"\",\n",
        "      \"Technique name\": \"\",\n",
        "      \"Quotes\": [\"\"],\n",
        "      \"Explanation\": \"\"\n",
        "    ]\n",
        "    </examples>\n",
        "\n",
        "    Do not include anything besides write the JSON.\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "  message = client.messages.create(\n",
        "      max_tokens=1024,\n",
        "      messages=[\n",
        "          {\n",
        "              \"role\": \"user\",\n",
        "              \"content\": prompt_with_example,\n",
        "          },\n",
        "          {\n",
        "            \"role\": \"assistant\",\n",
        "            \"content\": answer_we_expect,\n",
        "          },\n",
        "                    {\n",
        "              \"role\": \"user\",\n",
        "              \"content\": prompt,\n",
        "          },\n",
        "      ],\n",
        "      model=\"claude-3-sonnet-20240229\",\n",
        "      temperature=0,\n",
        "  )\n",
        "\n",
        "  return message"
      ],
      "metadata": {
        "id": "xC3Zp_bIrqCO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Prompting without techniques guide and with 2 example (WTG2E):**\n",
        "At this stage, the LLMs will receive a prompt that does not include the list of techniques from MITRE ATT&CK in order to examine the results of the models based on prior knowledge that has been trained. According to our request, the LLMs will classify the techniques according to the content of the rule.\n",
        "\n",
        "In addition, the prompt has two example (two shot)\n"
      ],
      "metadata": {
        "id": "s-8i8ebSpqxG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def WTG2E(snort_rule):\n",
        "\n",
        "  # prompt = f\"\"\"Q: You are an information security expert. Your task is to label IDS rules for MITRE ATT&CK techniques based on your cybersecurity knowledge. For the task, you are going to get a single Snort IDS rule and you will need to return the most relevant techniques from MITRE ATT&CK that are related to the rule.\n",
        "  #   Try to search based on keywords and based on the knowledge you have. For each technique include the following information as JSON in this order: 'Sid', 'Technique ID', 'Technique Name', 'Quotes', 'Explanation'.\n",
        "  #   Note: The value of the citation field should contain quotation marks from the data sets relevant to the mapped technique are the main reason you chose this technique to be correct. The value of the explanation should be your explanation of why you decided to give the technique and how it relates to the rule. The technique ID should be the official MITRE technique ID.\n",
        "  #   Please don't write anything but the JSON. Rule: \"alert tcp $EXTERNAL_NET $HTTP_PORTS -> $HOME_NET any ( msg:\"\"MALWARE-CNC Win.Trojan.GateKeylogger fake 404 response\"\"; flow:to_client,established; http_stat_code; content:\"\"200\"\"; http_stat_msg; content:\"\"OK\"\"; pkt_data; content:\"\">404 Not Found<\"\",fast_pattern,nocase; content:\"\" requested URL / was not found \"\"; metadata:impact_flag red,ruleset community; service:http; T1056; classtype:trojan-activity; sid:38563; rev:4; )\"\n",
        "  #   A: [\n",
        "  #       \"sid\": \"38563\",\n",
        "  #       \"Technique ID\": \"T1056\",\n",
        "  #       \"Technique name\": \"Input Capture\",\n",
        "  #       \"Quotes\": \"\\\"Input Capture techniques involve intercepting and capturing user input data, such as keystrokes, to obtain sensitive information. The rule indicates the presence of a Trojan (GateKeylogger) that mimics a '404 Not Found' error to disguise its communication with a command and control server, which is a common method used by keyloggers to stealthily capture input data.\\\"\",\n",
        "  #       \"Explanation\": \"This event is generated when activity relating to malware is detected.\"\n",
        "  #   ]\n",
        "\n",
        "  #   Q: You are an information security expert. Your task is to label IDS rules for MITRE ATT&CK techniques based on your cybersecurity knowledge. For the task, you are going to get a single Snort IDS rule and you will need to return the most relevant techniques from MITRE ATT&CK that are related to the rule.\n",
        "  #   Try to search based on keywords and based on the knowledge you have. For each technique include the following information as JSON in this order: 'Sid', 'Technique ID', 'Technique Name', 'Quotes', 'Explanation'.\n",
        "  #   Note: The value of the citation field should contain quotation marks from the data sets relevant to the mapped technique are the main reason you chose this technique to be correct. The value of the explanation should be your explanation of why you decided to give the technique and how it relates to the rule. The technique ID should be the official MITRE technique ID.\n",
        "  #   Please don't write anything but the JSON. Rule: \"alert tcp $EXTERNAL_NET $HTTP_PORTS -> $HOME_NET any ( msg:\"\"MALWARE-CNC Win.Trojan.GateKeylogger fake 404 response\"\"; flow:to_client,established; http_stat_code; content:\"\"200\"\"; http_stat_msg; content:\"\"OK\"\"; pkt_data; content:\"\">404 Not Found<\"\",fast_pattern,nocase; content:\"\" requested URL / was not found \"\"; metadata:impact_flag red,ruleset community; service:http; T1056; classtype:trojan-activity; sid:38563; rev:4; )\"\n",
        "  #   A: [\n",
        "  #       \"sid\": \"23934\",\n",
        "  #       \"Technique ID\": \"T1190\",\n",
        "  #       \"Technique name\": \"Exploit Public-Facing Application\",\n",
        "  #       \"Quotes\": \"\\\"Exploit Public-Facing Application techniques involve targeting vulnerabilities in externally facing applications to gain unauthorized access or execute arbitrary code. This rule detects an attempted blind SQL injection attack on the Symantec Web Gateway's 'blocked.php' page, which is a common method attackers use to exploit web applications by manipulating SQL queries.\\\"\",\n",
        "  #       \"Explanation\": \"SQL injection vulnerability in the management console in Symantec Web Gateway 5.0.x before 5.0.3.18 allows remote attackers to execute arbitrary SQL commands via unspecified vectors, related to a \"blind SQL injection\" issue.\"\n",
        "  #   ]\n",
        "\n",
        "  #   Q: You are an information security expert. Your task is to label IDS rules for MITRE ATT&CK techniques based on your cybersecurity knowledge. For the task, you are going to get a single Snort IDS rule and you will need to return the most relevant techniques from MITRE ATT&CK that are related to the rule.\n",
        "  #   Try to search based on keywords and based on the knowledge you have. For each technique include the following information as JSON in this order: 'Sid', 'Technique ID', 'Technique Name', 'Quotes', 'Explanation'.\n",
        "  #   Note: The value of the citation field should contain quotation marks from the data sets relevant to the mapped technique are the main reason you chose this technique to be correct. The value of the explanation should be your explanation of why you decided to give the technique and how it relates to the rule. The technique ID should be the official MITRE technique ID.\n",
        "  #   Please don't write anything but the JSON. Rule: {snort_rule}\n",
        "  #   A: \"\"\"\n",
        "\n",
        "  prompt_with_example_1 = f\"\"\"Q: I'm going to give you a Snort rule. Read the Snort rule carefully, because I'm going to given you a task about it. Here is the Snort rule: <snort_rule>\"alert tcp $EXTERNAL_NET $HTTP_PORTS -> $HOME_NET any ( msg:\"\"MALWARE-CNC Win.Trojan.GateKeylogger fake 404 response\"\"; flow:to_client,established; http_stat_code; content:\"\"200\"\"; http_stat_msg; content:\"\"OK\"\"; pkt_data; content:\"\">404 Not Found<\"\",fast_pattern,nocase; content:\"\" requested URL / was not found \"\"; metadata:impact_flag red,ruleset community; service:http; T1056; classtype:trojan-activity; sid:38563; rev:4; )\"</snort_rule>\n",
        "\n",
        "  First, your task is to return no more than 2 most relevant techniques from MITER ATT&CK that are related to the Snort rule.\n",
        "\n",
        "  Then, answer the task, for each technique include the following information as JSON in this order: 'Sid', 'Technique ID', 'Technique Name', 'Quotes', 'Explanation'.\n",
        "\n",
        "  Note: The value of the citation field should contain quotation marks from the data sets relevant to the mapped technique are the main reason you chose this technique to be correct. The value of the explanation should be your explanation of why you decided to give the technique and how it relates to the rule. The technique ID should be the official MITRE technique ID.\n",
        "\n",
        "\n",
        "  <examples>\n",
        "    [\n",
        "      \"sid\": \"\",\n",
        "      \"Technique ID\": \"\",\n",
        "      \"Technique name\": \"\",\n",
        "      \"Quotes\": [\"\"],\n",
        "      \"Explanation\": \"\"\n",
        "    ]\n",
        "    </examples>\n",
        "\n",
        "    Do not include anything besides write the JSON.\n",
        "    \"\"\"\n",
        "\n",
        "  answer_we_expect_1 = f\"\"\"\n",
        "    [\n",
        "        \"sid\": \"38563\",\n",
        "        \"Technique ID\": \"T1056\",\n",
        "        \"Technique name\": \"Input Capture\",\n",
        "        \"Quotes\": \"\\\"Input Capture techniques involve intercepting and capturing user input data, such as keystrokes, to obtain sensitive information. The rule indicates the presence of a Trojan (GateKeylogger) that mimics a '404 Not Found' error to disguise its communication with a command and control server, which is a common method used by keyloggers to stealthily capture input data.\\\"\",\n",
        "        \"Explanation\": \"This event is generated when activity relating to malware is detected.\"\n",
        "    ]\n",
        "  \"\"\"\n",
        "\n",
        "  prompt_with_example_2 = f\"\"\"Q: I'm going to give you a Snort rule. Read the Snort rule carefully, because I'm going to given you a task about it. Here is the Snort rule: <snort_rule>\"alert tcp $EXTERNAL_NET any -> $HOME_NET $HTTP_PORTS ( msg:\"\"SERVER-OTHER Apache Log4j logging remote code execution attempt\"\"; flow:to_server,established; http_header; content:\"\"upper\"\",fast_pattern,nocase; pcre:\"\"/(%(25)?24|\\x24)(%(25)?7b|\\x7b)upper(%(25)?3a|\\x3a)/i\"\"; metadata:policy balanced-ips drop,policy connectivity-ips drop,policy max-detect-ips drop,policy security-ips drop,ruleset community; service:http; classtype:attempted-user; gid:1; sid:58738; rev:5; )\"</snort_rule>\n",
        "\n",
        "  First, your task is to return no more than 2 most relevant techniques from MITER ATT&CK that are related to the Snort rule.\n",
        "\n",
        "  Then, answer the task, for each technique include the following information as JSON in this order: 'Sid', 'Technique ID', 'Technique Name', 'Quotes', 'Explanation'.\n",
        "\n",
        "  Note: The value of the citation field should contain quotation marks from the data sets relevant to the mapped technique are the main reason you chose this technique to be correct. The value of the explanation should be your explanation of why you decided to give the technique and how it relates to the rule. The technique ID should be the official MITRE technique ID.\n",
        "\n",
        "\n",
        "  <examples>\n",
        "    [\n",
        "      \"sid\": \"\",\n",
        "      \"Technique ID\": \"\",\n",
        "      \"Technique name\": \"\",\n",
        "      \"Quotes\": [\"\"],\n",
        "      \"Explanation\": \"\"\n",
        "    ]\n",
        "    </examples>\n",
        "\n",
        "    Do not include anything besides write the JSON.\n",
        "    \"\"\"\n",
        "\n",
        "  answer_we_expect_2 = f\"\"\"\n",
        "    [\n",
        "        \"sid\": \"23934\",\n",
        "        \"Technique ID\": \"T1190\",\n",
        "        \"Technique name\": \"Exploit Public-Facing Application\",\n",
        "        \"Quotes\": \"Adversaries may attempt to exploit a weakness in an Internet-facing host or system to initially access a network.\",\n",
        "        \"Explanation\": \"This rule looks for attempts to exploit a remote code execution vulnerability in Log4j's \"Lookup\" functionality.\"\n",
        "    ]\n",
        "  \"\"\"\n",
        "\n",
        "  prompt = f\"\"\"\n",
        "  I'm going to give you a Snort rule. Read the Snort rule carefully, because I'm going to given you a task about it. Here is the Snort rule: <snort_rule>{snort_rule}</snort_rule>\n",
        "\n",
        "  First, your task is to return no more than 2 most relevant techniques from MITER ATT&CK that are related to the Snort rule.\n",
        "\n",
        "  Then, answer the task, for each technique include the following information as JSON in this order: 'Sid', 'Technique ID', 'Technique Name', 'Quotes', 'Explanation'.\n",
        "\n",
        "  Note: The value of the citation field should contain quotation marks from the data sets relevant to the mapped technique are the main reason you chose this technique to be correct. The value of the explanation should be your explanation of why you decided to give the technique and how it relates to the rule. The technique ID should be the official MITRE technique ID.\n",
        "  \"\"\"\n",
        "\n",
        "\n",
        "\n",
        "  message = client.messages.create(\n",
        "      max_tokens=1024,\n",
        "      messages=[\n",
        "          {\n",
        "              \"role\": \"user\",\n",
        "              \"content\": prompt_with_example_1,\n",
        "          },\n",
        "          {\n",
        "            \"role\": \"assistant\",\n",
        "            \"content\": answer_we_expect_1,\n",
        "          },\n",
        "          {\n",
        "              \"role\": \"user\",\n",
        "              \"content\": prompt_with_example_2,\n",
        "          },\n",
        "          {\n",
        "            \"role\": \"assistant\",\n",
        "            \"content\": answer_we_expect_2,\n",
        "          },\n",
        "          {\n",
        "              \"role\": \"user\",\n",
        "              \"content\": prompt,\n",
        "          },\n",
        "      ],\n",
        "      model=\"claude-3-sonnet-20240229\",\n",
        "      temperature=0,\n",
        "  )\n",
        "\n",
        "  return message"
      ],
      "metadata": {
        "id": "U8VGDeYErsVu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pre collection data for TG"
      ],
      "metadata": {
        "id": "D4PEMeOAKNiN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def recursive_enter(path: str, file_list: list = None) -> list:\n",
        "    if file_list is None:\n",
        "        file_list = []\n",
        "\n",
        "    try:\n",
        "        os.chdir(path)  # Change path\n",
        "\n",
        "        items = os.listdir()  # List everything in the directory\n",
        "        for item in items:\n",
        "            full_path = os.path.join(path, item)\n",
        "\n",
        "            if full_path.endswith(\".json\"):\n",
        "                with open(full_path) as f:\n",
        "                    file_list.append(json.load(f))\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "\n",
        "    return file_list\n",
        "\n",
        "tacticFolder = \"/content/Labeling_IDS_to_MITRE/Semester_A/Extract data from MITRE ATTACK/techniques_split\"\n",
        "file_list = []\n",
        "MITRE_Technique = recursive_enter(tacticFolder, file_list)\n",
        "print(len(MITRE_Technique))\n",
        "os.chdir(\"/content/\")\n",
        "\n",
        "All_MITRE_Technique_json = None\n",
        "All_MITRE_Technique_json_path = \"/content/Labeling_IDS_to_MITRE/Semester_A/Extract data from MITRE ATTACK/combined_techniques_split.json\"\n",
        "# Open and read the JSON file\n",
        "with open(All_MITRE_Technique_json_path, 'r') as file:\n",
        "    All_MITRE_Technique_json = json.load(file)"
      ],
      "metadata": {
        "id": "rjLRg3BPKOFd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Prompting with techniques guide and without example (TGWE):**\n",
        "In the next step, we will provide the LLMs with the list of all the techniques from MITRE ATT&CK, to guarantee that the models are targeted to the present techniques, even the infrequently used ones. Each technique will include the technique number, the name of the technique and its description. The techniques will be provided to the models in the form of batches (due to the memory limit of the models) and after each batch we will ask him to classify the appropriate techniques from the list he received (if exist), finally we will unite the model's answers for each individual rule.\n"
      ],
      "metadata": {
        "id": "T0dV1xXnpqrv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def TGWE(snort_rule, techniques, limit):\n",
        "  if limit:\n",
        "    str_limit = \"First, your task is to return no more than 2 most relevant techniques from MITER ATT&CK that are related to the Snort rule.\"\n",
        "  else:\n",
        "    str_limit = \"First, find the techniques from MITRE ATT&CK that are most relevant to the Snort rule.\"\n",
        "\n",
        "\n",
        "  prePrompt = f\"\"\"You are an information security expert. Now I will provide you information about techniques from MITRE ATT&CK, you will use the information for a task you will receive later. Do not reply to the information you receive.\"\"\"\n",
        "\n",
        "  dataPrompt = f\"The information:\\n {str(techniques)}\"\n",
        "\n",
        "  # response_data = f\"\"\"Your task is to label IDS rules for MITRE ATT&CK techniques based on the information I have provided you. For the task, you are going to get a single Snort IDS rule and you will need to return the most relevant techniques associated with the rule from the information I provided you only.\n",
        "  #  Note 1: There is not necessarily a suitable technique in the information, return a technique if and only if it has an unambiguous relationship to the provided rule, if not return an empty JSON. For each technique include the following information as JSON in this order: 'Sid', 'Technique ID', 'Technique Name', 'Quotes', 'Explanation'.\n",
        "  #  Note 2: The value of the citation field should contain quotation marks from the data sets relevant to the mapped technique are the main reason you chose this technique to be correct. The value of the explanation should be your explanation of why you decided to give the technique and how it relates to the rule. The technique ID should be the official MITRE technique ID.\n",
        "  #  Please don't write anything but the JSON. Rule: {snort_rule}\"\"\"\n",
        "\n",
        "  response_data = f\"\"\"I'm going to give you a Snort rule. Read the Snort rule carefully, because I'm going to given you a task about it. Here is the Snort rule: <snort_rule>{snort_rule}</snort_rule>\n",
        "\n",
        "  {str_limit}\n",
        "\n",
        "  Then, answer the task, for each technique include the following information as JSON in this order: 'Sid', 'Technique ID', 'Technique Name', 'Quotes', 'Explanation'.\n",
        "\n",
        "  Note: The value of the citation field should contain quotation marks from the data sets relevant to the mapped technique are the main reason you chose this technique to be correct. The value of the explanation should be your explanation of why you decided to give the technique and how it relates to the rule. The technique ID should be the official MITRE technique ID.\n",
        "\n",
        "\n",
        "  <examples>\n",
        "    [\n",
        "      \"sid\": \"\",\n",
        "      \"Technique ID\": \"\",\n",
        "      \"Technique name\": \"\",\n",
        "      \"Quotes\": [\"\"],\n",
        "      \"Explanation\": \"\"\n",
        "    ]\n",
        "    </examples>\n",
        "\n",
        "    Do not include anything besides write the JSON.\n",
        "    \"\"\"\n",
        "\n",
        "  tg_data_list = prePrompt + dataPrompt + response_data\n",
        "\n",
        "  message = client.messages.create(\n",
        "      max_tokens=1024,\n",
        "      messages=[\n",
        "          {\n",
        "              \"role\": \"user\",\n",
        "              \"content\": tg_data_list,\n",
        "          }\n",
        "      ],\n",
        "      model=\"claude-3-sonnet-20240229\",\n",
        "      temperature=0,\n",
        "  )\n",
        "\n",
        "  return message\n",
        "\n"
      ],
      "metadata": {
        "id": "yvrlkLN6scwN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Prompting with techniques guide and with 1 example (TG1E):**\n",
        "In the next step, we will provide the LLMs with the list of all the techniques from MITRE ATT&CK, to guarantee that the models are targeted to the present techniques, even the infrequently used ones. Each technique will include the technique number, the name of the technique and its description. The techniques will be provided to the models in the form of batches (due to the memory limit of the models) and after each batch we will ask him to classify the appropriate techniques from the list he received (if exist), finally we will unite the model's answers for each individual rule.\n",
        "\n",
        "In addition, the prompt has one example (one shot)"
      ],
      "metadata": {
        "id": "9PDyuWeDpqkn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def TG1E(snort_rule, techniques, limit):\n",
        "  if limit:\n",
        "    str_limit = \"First, your task is to return no more than 2 most relevant techniques from MITER ATT&CK that are related to the Snort rule.\"\n",
        "  else:\n",
        "    str_limit = \"First, find the techniques from MITRE ATT&CK that are most relevant to the Snort rule.\"\n",
        "\n",
        "\n",
        "  prePrompt = f\"\"\"You are an information security expert. Now I will provide you information about techniques from MITRE ATT&CK, you will use the information for a task you will receive later. Do not reply to the information you receive.\"\"\"\n",
        "\n",
        "  dataPrompt = f\"The information:\\n {str(techniques)}\"\n",
        "\n",
        "  response_data = f\"\"\"Q: I'm going to give you a Snort rule. Read the Snort rule carefully, because I'm going to given you a task about it. Here is the Snort rule: <snort_rule>\"alert tcp $EXTERNAL_NET $HTTP_PORTS -> $HOME_NET any ( msg:\"\"MALWARE-CNC Win.Trojan.GateKeylogger fake 404 response\"\"; flow:to_client,established; http_stat_code; content:\"\"200\"\"; http_stat_msg; content:\"\"OK\"\"; pkt_data; content:\"\">404 Not Found<\"\",fast_pattern,nocase; content:\"\" requested URL / was not found \"\"; metadata:impact_flag red,ruleset community; service:http; T1056; classtype:trojan-activity; sid:38563; rev:4; )\"</snort_rule>\n",
        "\n",
        "  {str_limit}\n",
        "\n",
        "  Then, answer the task, for each technique include the following information as JSON in this order: 'Sid', 'Technique ID', 'Technique Name', 'Quotes', 'Explanation'.\n",
        "\n",
        "  Note: The value of the citation field should contain quotation marks from the data sets relevant to the mapped technique are the main reason you chose this technique to be correct. The value of the explanation should be your explanation of why you decided to give the technique and how it relates to the rule. The technique ID should be the official MITRE technique ID.\n",
        "\n",
        "\n",
        "  <examples>\n",
        "    [\n",
        "      \"sid\": \"\",\n",
        "      \"Technique ID\": \"\",\n",
        "      \"Technique name\": \"\",\n",
        "      \"Quotes\": [\"\"],\n",
        "      \"Explanation\": \"\"\n",
        "    ]\n",
        "    </examples>\n",
        "\n",
        "    Do not include anything besides write the JSON.\n",
        "    \"\"\"\n",
        "\n",
        "  tg_data_list = prePrompt + dataPrompt + response_data\n",
        "\n",
        "\n",
        "  answer_we_expect = f\"\"\"\n",
        "    [\n",
        "        \"sid\": \"38563\",\n",
        "        \"Technique ID\": \"T1056\",\n",
        "        \"Technique name\": \"Input Capture\",\n",
        "        \"Quotes\": \"\\\"Input Capture techniques involve intercepting and capturing user input data, such as keystrokes, to obtain sensitive information. The rule indicates the presence of a Trojan (GateKeylogger) that mimics a '404 Not Found' error to disguise its communication with a command and control server, which is a common method used by keyloggers to stealthily capture input data.\\\"\",\n",
        "        \"Explanation\": \"This event is generated when activity relating to malware is detected.\"\n",
        "    ]\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  prompt = f\"\"\"\n",
        "  I'm going to give you a Snort rule. Read the Snort rule carefully, because I'm going to given you a task about it. Here is the Snort rule: <snort_rule>{snort_rule}</snort_rule>\n",
        "\n",
        "  {str_limit}\n",
        "\n",
        "  Then, answer the task, for each technique include the following information as JSON in this order: 'Sid', 'Technique ID', 'Technique Name', 'Quotes', 'Explanation'.\n",
        "\n",
        "  Note: The value of the citation field should contain quotation marks from the data sets relevant to the mapped technique are the main reason you chose this technique to be correct. The value of the explanation should be your explanation of why you decided to give the technique and how it relates to the rule. The technique ID should be the official MITRE technique ID.\n",
        "\n",
        "\n",
        "  <examples>\n",
        "    [\n",
        "      \"sid\": \"\",\n",
        "      \"Technique ID\": \"\",\n",
        "      \"Technique name\": \"\",\n",
        "      \"Quotes\": [\"\"],\n",
        "      \"Explanation\": \"\"\n",
        "    ]\n",
        "    </examples>\n",
        "\n",
        "    Do not include anything besides write the JSON.\n",
        "    \"\"\"\n",
        "  tg_data_list_prompt = prePrompt + dataPrompt + prompt\n",
        "\n",
        "  message = client.messages.create(\n",
        "      max_tokens=1024,\n",
        "      messages=[\n",
        "          {\n",
        "              \"role\": \"user\",\n",
        "              \"content\": tg_data_list,\n",
        "          },\n",
        "          {\n",
        "            \"role\": \"assistant\",\n",
        "            \"content\": answer_we_expect,\n",
        "          },\n",
        "          {\n",
        "              \"role\": \"user\",\n",
        "              \"content\": tg_data_list_prompt,\n",
        "          },\n",
        "      ],\n",
        "      model=\"claude-3-sonnet-20240229\",\n",
        "      temperature=0,\n",
        "  )\n",
        "\n",
        "  return message\n"
      ],
      "metadata": {
        "id": "owtWxmWAsxsl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Prompting with techniques guide and with 2 example (TG2E):**\n",
        "In the next step, we will provide the LLMs with the list of all the techniques from MITRE ATT&CK, to guarantee that the models are targeted to the present techniques, even the infrequently used ones. Each technique will include the technique number, the name of the technique and its description. The techniques will be provided to the models in the form of batches (due to the memory limit of the models) and after each batch we will ask him to classify the appropriate techniques from the list he received (if exist), finally we will unite the model's answers for each individual rule.\n",
        "\n",
        "In addition, the prompt has two example (two shot)"
      ],
      "metadata": {
        "id": "7aOvvGzApqUQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def TG2E(snort_rule, techniques, limit):\n",
        "  if limit:\n",
        "    str_limit = \"First, your task is to return no more than 2 most relevant techniques from MITER ATT&CK that are related to the Snort rule.\"\n",
        "  else:\n",
        "    str_limit = \"First, find the techniques from MITRE ATT&CK that are most relevant to the Snort rule.\"\n",
        "\n",
        "\n",
        "  prePrompt = f\"\"\"You are an information security expert. Now I will provide you information about techniques from MITRE ATT&CK, you will use the information for a task you will receive later. Do not reply to the information you receive.\"\"\"\n",
        "\n",
        "  dataPrompt = f\"The information:\\n {str(techniques)}\"\n",
        "\n",
        "  response_data = f\"\"\"Q: I'm going to give you a Snort rule. Read the Snort rule carefully, because I'm going to given you a task about it. Here is the Snort rule: <snort_rule>\"alert tcp $EXTERNAL_NET $HTTP_PORTS -> $HOME_NET any ( msg:\"\"MALWARE-CNC Win.Trojan.GateKeylogger fake 404 response\"\"; flow:to_client,established; http_stat_code; content:\"\"200\"\"; http_stat_msg; content:\"\"OK\"\"; pkt_data; content:\"\">404 Not Found<\"\",fast_pattern,nocase; content:\"\" requested URL / was not found \"\"; metadata:impact_flag red,ruleset community; service:http; T1056; classtype:trojan-activity; sid:38563; rev:4; )\"</snort_rule>\n",
        "\n",
        "  {str_limit}\n",
        "\n",
        "  Then, answer the task, for each technique include the following information as JSON in this order: 'Sid', 'Technique ID', 'Technique Name', 'Quotes', 'Explanation'.\n",
        "\n",
        "  Note: The value of the citation field should contain quotation marks from the data sets relevant to the mapped technique are the main reason you chose this technique to be correct. The value of the explanation should be your explanation of why you decided to give the technique and how it relates to the rule. The technique ID should be the official MITRE technique ID.\n",
        "\n",
        "\n",
        "  <examples>\n",
        "    [\n",
        "      \"sid\": \"\",\n",
        "      \"Technique ID\": \"\",\n",
        "      \"Technique name\": \"\",\n",
        "      \"Quotes\": [\"\"],\n",
        "      \"Explanation\": \"\"\n",
        "    ]\n",
        "    </examples>\n",
        "\n",
        "    Do not include anything besides write the JSON.\n",
        "    \"\"\"\n",
        "\n",
        "  tg_data_list = prePrompt + dataPrompt + response_data\n",
        "\n",
        "\n",
        "  answer_we_expect_1 = f\"\"\"\n",
        "    [\n",
        "        \"sid\": \"38563\",\n",
        "        \"Technique ID\": \"T1056\",\n",
        "        \"Technique name\": \"Input Capture\",\n",
        "        \"Quotes\": \"\\\"Input Capture techniques involve intercepting and capturing user input data, such as keystrokes, to obtain sensitive information. The rule indicates the presence of a Trojan (GateKeylogger) that mimics a '404 Not Found' error to disguise its communication with a command and control server, which is a common method used by keyloggers to stealthily capture input data.\\\"\",\n",
        "        \"Explanation\": \"This event is generated when activity relating to malware is detected.\"\n",
        "    ]\n",
        "  \"\"\"\n",
        "\n",
        "  prompt_with_example_2 = f\"\"\"Q: I'm going to give you a Snort rule. Read the Snort rule carefully, because I'm going to given you a task about it. Here is the Snort rule: <snort_rule>\"alert tcp $EXTERNAL_NET any -> $HOME_NET $HTTP_PORTS ( msg:\"\"SERVER-OTHER Apache Log4j logging remote code execution attempt\"\"; flow:to_server,established; http_header; content:\"\"upper\"\",fast_pattern,nocase; pcre:\"\"/(%(25)?24|\\x24)(%(25)?7b|\\x7b)upper(%(25)?3a|\\x3a)/i\"\"; metadata:policy balanced-ips drop,policy connectivity-ips drop,policy max-detect-ips drop,policy security-ips drop,ruleset community; service:http; classtype:attempted-user; gid:1; sid:58738; rev:5; )\"</snort_rule>\n",
        "\n",
        "  {str_limit}\n",
        "\n",
        "  Then, answer the task, for each technique include the following information as JSON in this order: 'Sid', 'Technique ID', 'Technique Name', 'Quotes', 'Explanation'.\n",
        "\n",
        "  Note: The value of the citation field should contain quotation marks from the data sets relevant to the mapped technique are the main reason you chose this technique to be correct. The value of the explanation should be your explanation of why you decided to give the technique and how it relates to the rule. The technique ID should be the official MITRE technique ID.\n",
        "\n",
        "\n",
        "  <examples>\n",
        "    [\n",
        "      \"sid\": \"\",\n",
        "      \"Technique ID\": \"\",\n",
        "      \"Technique name\": \"\",\n",
        "      \"Quotes\": [\"\"],\n",
        "      \"Explanation\": \"\"\n",
        "    ]\n",
        "    </examples>\n",
        "\n",
        "    Do not include anything besides write the JSON.\n",
        "    \"\"\"\n",
        "\n",
        "  tg_data_list2 = prePrompt + dataPrompt + prompt_with_example_2\n",
        "\n",
        "  answer_we_expect_2 = f\"\"\"\n",
        "    [\n",
        "        \"sid\": \"23934\",\n",
        "        \"Technique ID\": \"T1190\",\n",
        "        \"Technique name\": \"Exploit Public-Facing Application\",\n",
        "        \"Quotes\": \"Adversaries may attempt to exploit a weakness in an Internet-facing host or system to initially access a network.\",\n",
        "        \"Explanation\": \"This rule looks for attempts to exploit a remote code execution vulnerability in Log4j's \"Lookup\" functionality.\"\n",
        "    ]\n",
        "  \"\"\"\n",
        "\n",
        "  prompt = f\"\"\"\n",
        "  I'm going to give you a Snort rule. Read the Snort rule carefully, because I'm going to given you a task about it. Here is the Snort rule: <snort_rule>{snort_rule}</snort_rule>\n",
        "\n",
        "  {str_limit}\n",
        "\n",
        "  Then, answer the task, for each technique include the following information as JSON in this order: 'Sid', 'Technique ID', 'Technique Name', 'Quotes', 'Explanation'.\n",
        "\n",
        "  Note: The value of the citation field should contain quotation marks from the data sets relevant to the mapped technique are the main reason you chose this technique to be correct. The value of the explanation should be your explanation of why you decided to give the technique and how it relates to the rule. The technique ID should be the official MITRE technique ID.\n",
        "  \"\"\"\n",
        "\n",
        "  tg_data_list_prompt = prePrompt + dataPrompt + prompt\n",
        "\n",
        "  message = client.messages.create(\n",
        "      max_tokens=1024,\n",
        "      messages=[\n",
        "          {\n",
        "              \"role\": \"user\",\n",
        "              \"content\": tg_data_list,\n",
        "          },\n",
        "          {\n",
        "            \"role\": \"assistant\",\n",
        "            \"content\": answer_we_expect_1,\n",
        "          },\n",
        "          {\n",
        "              \"role\": \"user\",\n",
        "              \"content\": tg_data_list2,\n",
        "          },\n",
        "          {\n",
        "            \"role\": \"assistant\",\n",
        "            \"content\": answer_we_expect_2,\n",
        "          },\n",
        "          {\n",
        "              \"role\": \"user\",\n",
        "              \"content\": tg_data_list_prompt,\n",
        "          },\n",
        "      ],\n",
        "      model=\"claude-3-sonnet-20240229\",\n",
        "      temperature=0,\n",
        "  )\n",
        "\n",
        "  return message"
      ],
      "metadata": {
        "id": "If-C7bUptAQd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Write to csv"
      ],
      "metadata": {
        "id": "QqzXpySOtBFs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write Zero Shot"
      ],
      "metadata": {
        "id": "vHnw97ACdI75"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def write_csv_ZS(filename, rule_dict):\n",
        "  # Define the field names\n",
        "  field_names = [\"Technique_id\", \"True_labels\"]\n",
        "\n",
        "  # Open the CSV file in write mode (truncating any existing content)\n",
        "  with open(filename, \"w\", newline=\"\") as csvfile: # \"prompting_without_techniques_guide.csv\"\n",
        "      # Create a DictWriter object with the specified field names\n",
        "      writer = csv.DictWriter(csvfile, fieldnames=field_names)\n",
        "\n",
        "      # Write the header row\n",
        "      writer.writeheader()\n",
        "\n",
        "      # Extract relevant data from each item and write it as a dictionary\n",
        "      counter = 0\n",
        "      for key, value in rule_dict.items():\n",
        "        text = clean_response(value)\n",
        "        technique_ids = []\n",
        "        print(text)\n",
        "\n",
        "        if \"'Sid\" in text:\n",
        "          # Define a regex pattern to switch single quotes to double quotes\n",
        "          pattern = re.compile(r\"((^|\\s)'((?:[^'\\\\]|\\\\.)*)'(?=[\\s.,:;!?)]))|(:\\s*'((?:[^'\\\\]|\\\\.)+)')\")\n",
        "          # Switch single quotes to double quotes\n",
        "          text = pattern.sub(lambda x: x.group().replace(\"'\", '\"'), text)\n",
        "\n",
        "          pattern = re.compile(r'\"\\S+\"[\\s\\.]|\\s\"[\\w\\s]*\"\\s')\n",
        "          text = re.sub(pattern, \"\", text)\n",
        "\n",
        "        # Extracting \"TXXXX\" numbers using regular expression\n",
        "        technique_ids = re.findall(r'[\\'\\\"](T\\d+(?:\\.\\d+)?)', text)\n",
        "\n",
        "        # Extracting \"Sid\"\n",
        "        match = re.search(r'[\\'\\\"][s|S]id[\\'\\\"]: [\\'\\\"](\\d+)[\\'\\\"]', text)\n",
        "        if match:\n",
        "            sid_number = match.group(1)\n",
        "\n",
        "\n",
        "        # Assuming each item has all necessary fields:\n",
        "        insertRow = {\n",
        "            \"Technique_id\": technique_ids,  # Handle potential absence\n",
        "            \"True_labels\": true_labels[counter],\n",
        "        }\n",
        "        writer.writerow(insertRow)\n",
        "        counter += 1\n"
      ],
      "metadata": {
        "id": "e4vK60PodJYx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write without techniques guide"
      ],
      "metadata": {
        "id": "aVCTBCt4wktp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def write_csv_WTG(filename, rule_dict):\n",
        "  # Define the field names\n",
        "  field_names = [\"Sid\", \"Response\", \"Technique_id\", \"True_labels\"]\n",
        "\n",
        "  # Open the CSV file in write mode (truncating any existing content)\n",
        "  with open(filename, \"w\", newline=\"\") as csvfile: # \"prompting_without_techniques_guide.csv\"\n",
        "      # Create a DictWriter object with the specified field names\n",
        "      writer = csv.DictWriter(csvfile, fieldnames=field_names)\n",
        "\n",
        "      # Write the header row\n",
        "      writer.writeheader()\n",
        "\n",
        "      # Extract relevant data from each item and write it as a dictionary\n",
        "      counter = 0\n",
        "      for key, value in rule_dict.items():\n",
        "        text = clean_response(value)\n",
        "        technique_ids = []\n",
        "        #print(text)\n",
        "\n",
        "        if \"'Sid\" in text:\n",
        "          # Define a regex pattern to switch single quotes to double quotes\n",
        "          pattern = re.compile(r\"((^|\\s)'((?:[^'\\\\]|\\\\.)*)'(?=[\\s.,:;!?)]))|(:\\s*'((?:[^'\\\\]|\\\\.)+)')\")\n",
        "          # Switch single quotes to double quotes\n",
        "          text = pattern.sub(lambda x: x.group().replace(\"'\", '\"'), text)\n",
        "\n",
        "          pattern = re.compile(r'\"\\S+\"[\\s\\.]|\\s\"[\\w\\s]*\"\\s')\n",
        "          text = re.sub(pattern, \"\", text)\n",
        "\n",
        "        # Extracting \"TXXXX\" numbers using regular expression\n",
        "        technique_ids = re.findall(r'[\\'\\\"](T\\d+(?:\\.\\d+)?)', text)\n",
        "\n",
        "        # Extracting \"Sid\"\n",
        "        match = re.search(r'[\\'\\\"][s|S]id[\\'\\\"]: [\\'\\\"](\\d+)[\\'\\\"]', text)\n",
        "        if match:\n",
        "            sid_number = match.group(1)\n",
        "\n",
        "\n",
        "        # Assuming each item has all necessary fields:\n",
        "        insertRow = {\n",
        "            \"Sid\": sid_number,\n",
        "            \"Response\": text,\n",
        "            \"Technique_id\": technique_ids,  # Handle potential absence\n",
        "            \"True_labels\": true_labels[counter],\n",
        "        }\n",
        "        writer.writerow(insertRow)\n",
        "        counter += 1\n"
      ],
      "metadata": {
        "id": "8O333P2lagRU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write with techniques guide"
      ],
      "metadata": {
        "id": "C2pGJjEHwqWA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import re\n",
        "\n",
        "headersCSV_TG = [\"Sid\", \"Response_11_Iteration\", \"Without_Prompt_Limit_Without_Competition_Without_Limit_Return\",\n",
        "                 \"Without_Prompt_Limit_Without_Competition_With_Limit_Return\",\n",
        "                 \"Response_Competition_1\", \"Response_Competition_2\", \"Response_Competition_3\",\n",
        "                 \"Without_Prompt_Limit_With_Competition_Without_Limit_Return\",\n",
        "                 \"Without_Prompt_Limit_With_Competition_With_Limit_Return\", \"True_labels\"]\n",
        "\n",
        "def init_file(fileName):\n",
        "  # Initial write to csv with header\n",
        "  with open(fileName, 'w', newline='') as csvfile: # 'prompting_with_techniques_guide.csv'\n",
        "      writer = csv.DictWriter(csvfile, fieldnames=headersCSV_TG)\n",
        "      writer.writeheader()\n",
        "\n",
        "def appendToCSV(rows_data, counter, fileName, technique_ids) -> None:\n",
        "    '''\n",
        "    rows_data -> {213: [<IPython.core.display.Markdown object>, <IPython.core.display.Markdown object>, ...]}\n",
        "    '''\n",
        "    all_technique, top_2_all_technique, all_competition, top_2_all_competition, tg_dict_Batch1, tg_dict_Batch2, tg_dict_Batch3 = technique_ids\n",
        "\n",
        "    # Open the CSV file in append mode to add new rows\n",
        "    with open(fileName, 'a', newline='') as csvfile:\n",
        "        writer = csv.DictWriter(csvfile, fieldnames=headersCSV_TG)\n",
        "\n",
        "        # Loop through each row and write data\n",
        "        for row, value in rows_data.items():\n",
        "            response_text = \"\"\n",
        "            for i in value:\n",
        "                text = clean_response(i)\n",
        "                response_text += text\n",
        "                #print(text)\n",
        "\n",
        "            insertRow = {\n",
        "                \"Sid\": row,\n",
        "                \"Response_11_Iteration\": response_text,\n",
        "                \"Without_Prompt_Limit_Without_Competition_Without_Limit_Return\": all_technique,\n",
        "                \"Without_Prompt_Limit_Without_Competition_With_Limit_Return\": top_2_all_technique,\n",
        "                \"Response_Competition_1\": tg_dict_Batch1,\n",
        "                \"Response_Competition_2\": tg_dict_Batch2,\n",
        "                \"Response_Competition_3\": tg_dict_Batch3,\n",
        "                \"Without_Prompt_Limit_With_Competition_Without_Limit_Return\": all_competition,\n",
        "                \"Without_Prompt_Limit_With_Competition_With_Limit_Return\": top_2_all_competition,\n",
        "                \"True_labels\": true_labels[counter]\n",
        "            }\n",
        "\n",
        "            # Write the row to the CSV file\n",
        "            writer.writerow(insertRow)\n"
      ],
      "metadata": {
        "id": "fsUbfkVjhPqn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# WTG - Generic"
      ],
      "metadata": {
        "id": "Au3iaHvfg2_g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def WTG(functionName, rules_list):\n",
        "  rule_dict = {}\n",
        "  max_retries = 3  # Maximum number of retries\n",
        "\n",
        "  for index, rule in enumerate(rules_list):\n",
        "      retries = 0\n",
        "      print(f\"------------------{index}-----------------------\")\n",
        "      print(rule)\n",
        "      while retries < max_retries:\n",
        "          try:\n",
        "              res = functionName(rule)\n",
        "              text = str(res.content)\n",
        "              # Check if the text contains the desired pattern\n",
        "              t_numbers = re.findall(r'[\\'\\\"](T\\d+(?:\\.\\d+)?)', text)\n",
        "              if t_numbers:  # If the pattern is found\n",
        "                  rule_dict[data['Sid'][index]] = to_markdown(text)\n",
        "                  break  # Break out of the retry loop if successful\n",
        "              else:\n",
        "                  print(\"Desired pattern not found in the text. Retrying...\")\n",
        "                  retries += 1\n",
        "                  time.sleep(1)  # Wait for a short duration before retrying\n",
        "\n",
        "              #time.sleep(15) # remove after we have money :)\n",
        "          except Exception as e:\n",
        "              print(f\"An error occurred: {e}\")\n",
        "              retries += 1\n",
        "              if retries < max_retries:\n",
        "                  print(f\"Retrying... ({retries}/{max_retries})\")\n",
        "                  time.sleep(1)  # Wait for a short duration before retrying\n",
        "              else:\n",
        "                  print(\"Max retries reached. Unable to process this rule.\")\n",
        "\n",
        "  # If sending fails, attempt to send again\n",
        "  try:\n",
        "      # Code to send data\n",
        "      pass\n",
        "  except Exception as e:\n",
        "      print(f\"Sending failed: {e}\")\n",
        "      # Retry sending here\n",
        "\n",
        "  return rule_dict\n"
      ],
      "metadata": {
        "id": "g3PW59B_oaqu",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TG - Generic"
      ],
      "metadata": {
        "id": "zVkzHkKEysVX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_the_most_relevate_technique(tg_dict):\n",
        "    technique_ids = []\n",
        "    for row, value in tg_dict.items():\n",
        "        response_text = \"\"\n",
        "        for i in value:\n",
        "            text = clean_response(i)\n",
        "            response_text += text\n",
        "            try:\n",
        "                # Extracting \"TXXXX\" numbers using regular expression\n",
        "                technique_ids.extend(re.findall(r'[\\'\\\"](T\\d+(?:\\.\\d+)?)', text))\n",
        "            except Exception as e:\n",
        "                print(f\"Error extracting technique IDs: {e}\")\n",
        "    return technique_ids\n",
        "\n",
        "\n",
        "def stratification():\n",
        "  import ast\n",
        "\n",
        "  technique_counts = (data['technique ids'].value_counts())\n",
        "  # Converting the Series to a dictionary\n",
        "  technique_counts_dict = technique_counts.to_dict()\n",
        "  #print(technique_counts_dict)\n",
        "\n",
        "  # Initialize the new dictionary\n",
        "  new_data = {}\n",
        "  # Iterate through the original dictionary\n",
        "  for key, value in technique_counts_dict.items():\n",
        "      # Convert the string key to a list\n",
        "      techniques = ast.literal_eval(key)\n",
        "      # Iterate through the techniques in the list\n",
        "      for technique in techniques:\n",
        "          # Add the technique to the new dictionary\n",
        "          if technique in new_data:\n",
        "              new_data[technique] += value\n",
        "          else:\n",
        "              new_data[technique] = value\n",
        "\n",
        "  sorted_data = dict(sorted(new_data.items(), key=lambda item: item[1], reverse=True))\n",
        "  # Print the new dictionary\n",
        "  return sorted_data\n",
        "\n",
        "\n",
        "def tg_split_data(functionName, rules_list_index, index, fileName, limit):\n",
        "\n",
        "  for rule in rules_list_index:\n",
        "    print(f\"index {index} \\t Sid: {data['Sid'][index]}\")\n",
        "\n",
        "    tg_dict = {}\n",
        "    count = 0 #####\n",
        "    response_tg_dict_11_iteration = \"\"\n",
        "    for batch in MITRE_Technique: # 11 files\n",
        "      res = functionName(rule, batch, limit)\n",
        "      sid = data['Sid'][index]\n",
        "      if sid not in tg_dict:\n",
        "        tg_dict[sid] = []\n",
        "      try:\n",
        "        tg_dict[sid].append(to_markdown(str(res.content)))\n",
        "      except:\n",
        "        tg_dict[sid].append(to_markdown(\"{}\"))\n",
        "      print(f\"~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~{count}~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\") #####\n",
        "      print(to_markdown(str(res.content)))\n",
        "      count += 1 #######\n",
        "      #time.sleep(15)\n",
        "    response_tg_dict_11_iteration = tg_dict\n",
        "\n",
        "\n",
        "\n",
        "    # Get up to 3 rules (STATIC)\n",
        "    new_batch = []\n",
        "    technique_ids_from_11_batchs = get_the_most_relevate_technique(tg_dict)\n",
        "    for technique_id in technique_ids_from_11_batchs:\n",
        "        if technique_id in All_MITRE_Technique_json[0]:\n",
        "            new_batch.append((technique_id, All_MITRE_Technique_json[0][technique_id]))\n",
        "    new_dict = dict(new_batch)\n",
        "    print(new_dict)\n",
        "\n",
        "\n",
        "\n",
        "    # get the most frequency from top_2_new_batch:\n",
        "    res_stratification = stratification()\n",
        "    # Filter keys from res_stratification that are present in new_batch\n",
        "    filtered_keys = [key for key in new_dict.keys() if key in res_stratification.keys()]\n",
        "\n",
        "    # Sort the filtered keys based on counts in res_stratification\n",
        "    sorted_keys = sorted(filtered_keys, key=res_stratification.get, reverse=True)\n",
        "\n",
        "    # Get the top two keys\n",
        "    top_2_new_batch = sorted_keys[:2]\n",
        "\n",
        "\n",
        "\n",
        "    # Run new_batch 3 times\n",
        "    dictionary_of_rules = {}\n",
        "    tg_dict = {}\n",
        "\n",
        "    tg_dict_Batch1 = {}\n",
        "    tg_dict_Batch2 = {}\n",
        "    tg_dict_Batch3 = {}\n",
        "\n",
        "    for epoch in range(3):\n",
        "        tg_dict = {}\n",
        "        #time.sleep(1)\n",
        "        res = functionName(rule, new_dict, limit)\n",
        "        sid = data['Sid'][index]\n",
        "        if sid not in tg_dict:\n",
        "            tg_dict[sid] = []\n",
        "        try:\n",
        "            tg_dict[sid].append(to_markdown(str(res.content)))\n",
        "        except:\n",
        "            tg_dict[sid].append(to_markdown(\"{}\"))\n",
        "\n",
        "        inner_technique_ids = get_the_most_relevate_technique(tg_dict)\n",
        "        for technique in inner_technique_ids:\n",
        "            if technique not in dictionary_of_rules:\n",
        "                dictionary_of_rules[technique] = 1\n",
        "            else:\n",
        "                dictionary_of_rules[technique] += 1\n",
        "        print(dictionary_of_rules)\n",
        "        print(f\"~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~BATCH {epoch + 1}~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\")\n",
        "\n",
        "        if (epoch == 0):\n",
        "          tg_dict_Batch1[sid] = str(res.content)\n",
        "        elif (epoch == 1):\n",
        "          tg_dict_Batch2[sid] = str(res.content)\n",
        "        else:\n",
        "          tg_dict_Batch3[sid] = str(res.content)\n",
        "\n",
        "\n",
        "    if dictionary_of_rules: # This checks if the dictionary is empty\n",
        "      # Step 1: Find the maximum value in dictionary_of_rules\n",
        "      max_number_value = max(dictionary_of_rules.values())\n",
        "\n",
        "      # Step 2: Collect all keys with the maximum value\n",
        "      max_techniuqeId_keys = [key for key, value in dictionary_of_rules.items() if value == max_number_value]\n",
        "      if len(max_techniuqeId_keys) == 1:\n",
        "        sorted_values = sorted(dictionary_of_rules.values(), reverse=True)\n",
        "\n",
        "        # Get the second highest value\n",
        "        if len(sorted_values) >= 2:\n",
        "            second_max_value = sorted_values[1]\n",
        "            second_max_techniuqeId_keys = [key for key, value in dictionary_of_rules.items() if value == second_max_value]\n",
        "\n",
        "            if len(second_max_techniuqeId_keys) >= 2:\n",
        "              res_stratification = stratification()\n",
        "              # Find the key with the highest count in the res_stratification dictionary\n",
        "              max_count_key = max(res_stratification, key=res_stratification.get)\n",
        "              max_techniuqeId_keys.extend(max_count_key)\n",
        "            else:\n",
        "              max_techniuqeId_keys.extend(second_max_techniuqeId_keys)\n",
        "\n",
        "      elif len(max_techniuqeId_keys) > 2:\n",
        "        res_stratification = stratification()\n",
        "\n",
        "        keys_from_dict1 = set(dictionary_of_rules.keys())\n",
        "        filtered_dict2 = {key: value for key, value in res_stratification.items() if key in keys_from_dict1}\n",
        "        sorted_keys = sorted(filtered_dict2, key=filtered_dict2.get, reverse=True)\n",
        "        max_techniuqeId_keys = sorted_keys[:2]\n",
        "\n",
        "    else:\n",
        "      max_techniuqeId_keys = []\n",
        "\n",
        "\n",
        "\n",
        "    # Write to CSV\n",
        "    \"\"\"\n",
        "    response_tg_dict_11_iteration => all content from 11 iteration\n",
        "\n",
        "      **Without Competition**\n",
        "        new_batch => All techniques iterating from 11 iterations on one SNORT rule.\n",
        "        top_2_new_batch => From new_batch return the most 2 frequency.\n",
        "\n",
        "      **With Competition**\n",
        "        dictionary_of_rules.keys() => All techniques iterating from 3 batch.\n",
        "        max_techniuqeId_keys => From Batch return the most 2 frequency.\n",
        "    \"\"\"\n",
        "\n",
        "    technique_ids = (list(new_dict.keys()), top_2_new_batch, list(dictionary_of_rules.keys()), max_techniuqeId_keys, tg_dict_Batch1, tg_dict_Batch2, tg_dict_Batch3)\n",
        "    appendToCSV(response_tg_dict_11_iteration, index, fileName, technique_ids)\n",
        "    index += 1"
      ],
      "metadata": {
        "id": "WcvPIziJhRkA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run Experiments"
      ],
      "metadata": {
        "id": "-HzQQDPKTX32"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "without data"
      ],
      "metadata": {
        "id": "13rT0dwxTr2-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# #  Without Example Without Techniuqes Guide\n",
        "# rule_dict_ZS = WTG(ZS, rules_list)\n",
        "# write_csv_ZS(\"zero_shot.csv\", rule_dict_ZS)\n",
        "\n",
        "\n",
        "#  # Without Example Without Techniuqes Guide\n",
        "# rule_dict_WTG = WTG(WTGWE, rules_list)\n",
        "# write_csv_WTG(\"prompting_without_techniques_guide_zero_shot_with_limit.csv\", rule_dict_WTG)\n",
        "\n",
        "\n",
        "#  # With 1 Example Without Techniuqes Guide\n",
        "# rule_dict_WTG1E = WTG(WTG1E, rules_list)\n",
        "# write_csv_WTG(\"prompting_without_techniques_guide_one_shot_with_limit.csv\", rule_dict_WTG1E)\n",
        "\n",
        "\n",
        " # With 2 Example Without Techniuqes Guide\n",
        "rule_dict_WTG2E = WTG(WTG2E, rules_list)\n",
        "write_csv_WTG(\"prompting_without_techniques_guide_two_shot_with_limit.csv\", rule_dict_WTG2E)"
      ],
      "metadata": {
        "id": "3Nq8HFLITwpN",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "with data"
      ],
      "metadata": {
        "id": "cTiGJm4eTtv1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# fileName = 'prompting_with_techniques_guide_zero_shot_False.csv' #0\n",
        "fileName = 'prompting_with_techniques_guide_one_shot_False.csv' #1\n",
        "# fileName = 'prompting_with_techniques_guide_two_shot_False.csv' #2"
      ],
      "metadata": {
        "id": "nvBEnTKrB5DG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run this only for the first time to create the file!!\n",
        "init_file(fileName)"
      ],
      "metadata": {
        "id": "oKf380CSB7m-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  # Without Example With Techniuqes Guide\n",
        "# rule_dict_TGWE_01 = rules_list[185:] # index 0-99\n",
        "# tg_split_data(TGWE, rule_dict_TGWE_01, 185, fileName, False)\n",
        "\n",
        "# rule_dict_TGWE_02 = rules_list[100:200] # index 100-199\n",
        "# tg_split_data(TGWE, rule_dict_TGWE_02, 100, fileName)\n",
        "\n",
        "# rule_dict_TGWE_03 = rules_list[200:] # index 200-299\n",
        "# tg_split_data(TGWE, rule_dict_TGWE_03, 200, fileName)\n",
        "\n",
        "\n",
        "\n",
        "# With 1 Example With Techniuqes Guide\n",
        "rule_dict_TG1E_01 = rules_list[7:] # index 0-99\n",
        "tg_split_data(TG1E, rule_dict_TG1E_01, 7, fileName, False)\n",
        "\n",
        "# rule_dict_TG1E_02 = rules_list[100:200] # index 100-199\n",
        "# tg_split_data(TG1E, rule_dict_TG1E_02, 100, fileName)\n",
        "\n",
        "# rule_dict_TG1E_03 = rules_list[200:] # index 200-299\n",
        "# tg_split_data(TG1E, rule_dict_TG1E_03, 200, fileName)\n",
        "\n",
        "\n",
        "\n",
        "#  # With 2 Example With Techniuqes Guide\n",
        "# rule_dict_TG2E_01 = rules_list # index 0-99\n",
        "# tg_split_data(TG2E, rule_dict_TG2E_01, 0, fileName, False)\n",
        "\n",
        "# rule_dict_TG2E_02 = rules_list[100:200] # index 100-199\n",
        "# tg_split_data(TG2E, rule_dict_TG2E_02, 100, fileName)\n",
        "\n",
        "# rule_dict_TG2E_03 = rules_list[200:] # index 200-299\n",
        "# tg_split_data(TG2E, rule_dict_TG2E_03, 200, fileName)"
      ],
      "metadata": {
        "id": "0pKRMVH_hUpQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5b51b180-005c-4776-c95a-747d158dc51c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "index 3 \t Sid: 1129\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~0~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "<IPython.core.display.Markdown object>\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~1~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "<IPython.core.display.Markdown object>\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~2~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "<IPython.core.display.Markdown object>\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~3~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "<IPython.core.display.Markdown object>\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~4~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "<IPython.core.display.Markdown object>\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~5~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "<IPython.core.display.Markdown object>\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~6~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "<IPython.core.display.Markdown object>\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~7~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "<IPython.core.display.Markdown object>\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~8~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "<IPython.core.display.Markdown object>\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~9~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "<IPython.core.display.Markdown object>\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~10~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "<IPython.core.display.Markdown object>\n",
            "{'T1046': ['Network Service Discovery', 'Adversaries may attempt to get a listing of services running on remote hosts and local network infrastructure devices, including those that may be vulnerable to remote software exploitation'], 'T1083': ['File and Directory Discovery', 'Adversaries may enumerate files and directories or may search in specific locations of a host or network share for certain information within a file system'], 'T1036': ['Masquerading', 'Adversaries may attempt to manipulate features of their artifacts to make them appear legitimate or benign to users and/or security tools']}\n",
            "{'T1083': 1}\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~BATCH 1~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "{'T1083': 3}\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~BATCH 2~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "{'T1083': 6}\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~BATCH 3~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "index 4 \t Sid: 27967\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~0~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "<IPython.core.display.Markdown object>\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~1~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "<IPython.core.display.Markdown object>\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~2~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "<IPython.core.display.Markdown object>\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~3~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "<IPython.core.display.Markdown object>\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~4~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "<IPython.core.display.Markdown object>\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~5~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "<IPython.core.display.Markdown object>\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~6~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "<IPython.core.display.Markdown object>\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~7~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "<IPython.core.display.Markdown object>\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~8~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "<IPython.core.display.Markdown object>\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~9~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "<IPython.core.display.Markdown object>\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~10~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "<IPython.core.display.Markdown object>\n",
            "{'T1190': ['Exploit Public-Facing Application', 'Adversaries may attempt to exploit a weakness in an Internet-facing host or system to initially access a network'], 'T1210': ['Exploitation of Remote Services', 'Adversaries may exploit remote services to gain unauthorized access to internal systems once inside of a network'], 'T1105': ['Ingress Tool Transfer', 'Adversaries may transfer tools or other files from an external system into a compromised environment'], 'T1036': ['Masquerading', 'Adversaries may attempt to manipulate features of their artifacts to make them appear legitimate or benign to users and/or security tools']}\n",
            "{'T1190': 1, 'T1105': 1}\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~BATCH 1~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "{'T1190': 3, 'T1105': 3}\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~BATCH 2~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "{'T1190': 6, 'T1105': 6}\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~BATCH 3~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "index 5 \t Sid: 29869\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~0~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "<IPython.core.display.Markdown object>\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~1~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "<IPython.core.display.Markdown object>\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~2~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "<IPython.core.display.Markdown object>\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~3~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "<IPython.core.display.Markdown object>\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~4~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "<IPython.core.display.Markdown object>\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~5~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "<IPython.core.display.Markdown object>\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~6~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "<IPython.core.display.Markdown object>\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~7~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "<IPython.core.display.Markdown object>\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~8~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "<IPython.core.display.Markdown object>\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~9~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "<IPython.core.display.Markdown object>\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~10~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "<IPython.core.display.Markdown object>\n",
            "{'T1027': ['Obfuscated Files or Information', 'Adversaries may attempt to make an executable or file difficult to discover or analyze by encrypting, encoding, or otherwise obfuscating its contents on the system or in transit'], 'T1566': ['Phishing', 'Adversaries may send phishing messages to gain access to victim systems'], 'T1190': ['Exploit Public-Facing Application', 'Adversaries may attempt to exploit a weakness in an Internet-facing host or system to initially access a network'], 'T1606': ['Forge Web Credentials', 'Adversaries may forge credential materials that can be used to gain access to web applications or Internet services'], 'T1036': ['Masquerading', 'Adversaries may attempt to manipulate features of their artifacts to make them appear legitimate or benign to users and/or security tools']}\n",
            "{'T1566': 1, 'T1036': 1}\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~BATCH 1~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "{'T1566': 3, 'T1036': 3}\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~BATCH 2~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "{'T1566': 6, 'T1036': 6}\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~BATCH 3~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "index 6 \t Sid: 31807\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~0~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "<IPython.core.display.Markdown object>\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~1~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "<IPython.core.display.Markdown object>\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~2~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "<IPython.core.display.Markdown object>\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~3~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "<IPython.core.display.Markdown object>\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~4~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "<IPython.core.display.Markdown object>\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~5~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "<IPython.core.display.Markdown object>\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~6~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "<IPython.core.display.Markdown object>\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~7~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "<IPython.core.display.Markdown object>\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~8~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "<IPython.core.display.Markdown object>\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~9~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "<IPython.core.display.Markdown object>\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~10~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "<IPython.core.display.Markdown object>\n",
            "{'T1041': ['Exfiltration Over C2 Channel', 'Adversaries may steal data by exfiltrating it over an existing command and control channel'], 'T1048': ['Exfiltration Over Alternative Protocol', 'Adversaries may steal data by exfiltrating it over a different protocol than that of the existing command and control channel'], 'T1029': ['Scheduled Transfer', 'Adversaries may schedule data exfiltration to be performed only at certain times of day or at certain intervals'], 'T1020': ['Automated Exfiltration', 'Adversaries may exfiltrate data, such as sensitive documents, through the use of automated processing after being gathered during Collection'], 'T1105': ['Ingress Tool Transfer', 'Adversaries may transfer tools or other files from an external system into a compromised environment'], 'T1070': ['Indicator Removal', 'Adversaries may delete or modify artifacts generated within systems to remove evidence of their presence or hinder defenses'], 'T1102': ['Web Service', 'Adversaries may use an existing, legitimate external Web service as a means for relaying data to/from a compromised system'], 'T1078': ['Valid Accounts', 'Adversaries may obtain and abuse credentials of existing accounts as a means of gaining Initial Access, Persistence, Privilege Escalation, or Defense Evasion'], 'T1071': ['Application Layer Protocol', 'Adversaries may communicate using OSI application layer protocols to avoid detection/network filtering by blending in with existing traffic'], 'T1030': ['Data Transfer Size Limits', 'An adversary may exfiltrate data in fixed size chunks instead of whole files or limit packet sizes below certain thresholds']}\n",
            "{'T1041': 1, 'T1048': 1}\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~BATCH 1~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "{'T1041': 3, 'T1048': 3}\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~BATCH 2~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "{'T1041': 6, 'T1048': 6}\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~BATCH 3~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "index 7 \t Sid: 58751\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~0~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "<IPython.core.display.Markdown object>\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~1~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "<IPython.core.display.Markdown object>\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~2~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "<IPython.core.display.Markdown object>\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RateLimitError",
          "evalue": "Error code: 429 - {'type': 'error', 'error': {'type': 'rate_limit_error', 'message': 'Number of request tokens has exceeded your daily rate limit (https://docs.anthropic.com/en/api/rate-limits); see the response headers for current usage. Please reduce the prompt length or the maximum tokens requested, or try again later. You may also contact sales at https://www.anthropic.com/contact-sales to discuss your options for a rate limit increase.'}}",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-45-1fbf009ea1e8>\u001b[0m in \u001b[0;36m<cell line: 15>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# With 1 Example With Techniuqes Guide\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mrule_dict_TG1E_01\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrules_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# index 0-99\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mtg_split_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTG1E\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrule_dict_TG1E_01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfileName\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# rule_dict_TG1E_02 = rules_list[100:200] # index 100-199\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-38-376c61e3a577>\u001b[0m in \u001b[0;36mtg_split_data\u001b[0;34m(functionName, rules_list_index, index, fileName, limit)\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0mresponse_tg_dict_11_iteration\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mMITRE_Technique\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# 11 files\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m       \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunctionName\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m       \u001b[0msid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Sid'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0msid\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtg_dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-26-1c89d8feb3ad>\u001b[0m in \u001b[0;36mTG1E\u001b[0;34m(snort_rule, techniques, limit)\u001b[0m\n\u001b[1;32m     70\u001b[0m   \u001b[0mtg_data_list_prompt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprePrompt\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdataPrompt\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mprompt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m   message = client.messages.create(\n\u001b[0m\u001b[1;32m     73\u001b[0m       \u001b[0mmax_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m       messages=[\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/anthropic/_utils/_utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    275\u001b[0m                         \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"Missing required argument: {quote(missing[0])}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/anthropic/resources/messages.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self, max_tokens, messages, model, metadata, stop_sequences, stream, system, temperature, tool_choice, tools, top_k, top_p, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mhttpx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTimeout\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mNotGiven\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m600\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    898\u001b[0m     ) -> Message | Stream[RawMessageStreamEvent]:\n\u001b[0;32m--> 899\u001b[0;31m         return self._post(\n\u001b[0m\u001b[1;32m    900\u001b[0m             \u001b[0;34m\"/v1/messages\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    901\u001b[0m             body=maybe_transform(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/anthropic/_base_client.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1237\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mto_httpx_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m         )\n\u001b[0;32m-> 1239\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mResponseT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_cls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_cls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     def patch(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/anthropic/_base_client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    919\u001b[0m         \u001b[0mstream_cls\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_StreamT\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m     ) -> ResponseT | _StreamT:\n\u001b[0;32m--> 921\u001b[0;31m         return self._request(\n\u001b[0m\u001b[1;32m    922\u001b[0m             \u001b[0mcast_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m             \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/anthropic/_base_client.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1002\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mretries\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_retry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1003\u001b[0m                 \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1004\u001b[0;31m                 return self._retry_request(\n\u001b[0m\u001b[1;32m   1005\u001b[0m                     \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m                     \u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/anthropic/_base_client.py\u001b[0m in \u001b[0;36m_retry_request\u001b[0;34m(self, options, cast_to, remaining_retries, response_headers, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1050\u001b[0m         \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1051\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1052\u001b[0;31m         return self._request(\n\u001b[0m\u001b[1;32m   1053\u001b[0m             \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1054\u001b[0m             \u001b[0mcast_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/anthropic/_base_client.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1002\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mretries\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_retry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1003\u001b[0m                 \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1004\u001b[0;31m                 return self._retry_request(\n\u001b[0m\u001b[1;32m   1005\u001b[0m                     \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m                     \u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/anthropic/_base_client.py\u001b[0m in \u001b[0;36m_retry_request\u001b[0;34m(self, options, cast_to, remaining_retries, response_headers, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1050\u001b[0m         \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1051\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1052\u001b[0;31m         return self._request(\n\u001b[0m\u001b[1;32m   1053\u001b[0m             \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1054\u001b[0m             \u001b[0mcast_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/anthropic/_base_client.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1017\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1018\u001b[0m             \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Re-raising status error\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1019\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_status_error_from_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1020\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m         return self._process_response(\n",
            "\u001b[0;31mRateLimitError\u001b[0m: Error code: 429 - {'type': 'error', 'error': {'type': 'rate_limit_error', 'message': 'Number of request tokens has exceeded your daily rate limit (https://docs.anthropic.com/en/api/rate-limits); see the response headers for current usage. Please reduce the prompt length or the maximum tokens requested, or try again later. You may also contact sales at https://www.anthropic.com/contact-sales to discuss your options for a rate limit increase.'}}"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation\n",
        "\n",
        "\n",
        "*   Persicion\n",
        "*   Recall\n",
        "*   F-1\n",
        "\n"
      ],
      "metadata": {
        "id": "b4KI1_Ihg8Gr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import ast\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import math\n",
        "\n",
        "def evaluation(true_labels, predicted_labels, is_printable):\n",
        "  results = []\n",
        "  recall = []\n",
        "  precision = []\n",
        "  f1 = []\n",
        "\n",
        "\n",
        "  for i in range(len(true_labels)):\n",
        "    trueList = ast.literal_eval(true_labels[i])\n",
        "    predList = ast.literal_eval(predicted_labels[i])\n",
        "    # Extract only the 'TXXXX' part from each string in the list\n",
        "    predList = [item.split('.')[0] if '.' in item else item for item in predList]\n",
        "    intersection = set(trueList).intersection(set(predList))\n",
        "    #print(list(intersection))\n",
        "    if (len(predList) != 0):\n",
        "      recall.append(len(intersection) / len(set(trueList)))\n",
        "      precision.append(len(intersection) / len(set(predList)))\n",
        "      try:\n",
        "        f1.append((2 * precision[i] * recall[i]) / (recall[i] + precision[i]))\n",
        "      except:\n",
        "        f1.append(0)\n",
        "\n",
        "    ####### the real\n",
        "    else:\n",
        "      recall.append(0)\n",
        "      precision.append(0)\n",
        "      f1.append(0)\n",
        "\n",
        "  # Avg.\n",
        "  average_recall = sum(recall) / len(recall)\n",
        "  average_precision = sum(precision) / len(precision)\n",
        "  average_f1 = (2 * average_recall * average_precision) / (average_recall + average_precision)\n",
        "\n",
        "  if is_printable:\n",
        "    print(\"Metric    |   Score\")\n",
        "    print(\"-------------------\")\n",
        "    print(f\"Precision |   {average_precision:.2f}\")\n",
        "    print(f\"Recall    |   {average_recall:.2f}\")\n",
        "    print(f\"F1 Score  |   {average_f1:.2f}\")\n",
        "  else:\n",
        "    results.append((average_precision, average_recall, average_f1))\n",
        "    return results\n"
      ],
      "metadata": {
        "id": "WlJZ7D0Pg8zQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ZS"
      ],
      "metadata": {
        "id": "qhl0OOPpdQ4Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loadData = pd.read_csv(\"zero_shot.csv\")\n",
        "true_labels_ZS = loadData['True_labels']\n",
        "predicted_labels = loadData['Technique_id']\n",
        "\n",
        "evaluation(true_labels_ZS, predicted_labels, True)\n"
      ],
      "metadata": {
        "id": "g3sTHwY7dSMR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b73c0e07-9cf5-47c5-a010-51aeb2d21462"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Metric    |   Score\n",
            "-------------------\n",
            "Precision |   0.18\n",
            "Recall    |   0.23\n",
            "F1 Score  |   0.20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### WTGWE"
      ],
      "metadata": {
        "id": "AvJSwkHdzDvv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loadData = pd.read_csv(\"prompting_without_techniques_guide_zero_shot.csv\")\n",
        "true_labels_WTGWE = loadData['True_labels']\n",
        "predicted_labels = loadData['Technique_id']\n",
        "\n",
        "evaluation(true_labels_WTGWE, predicted_labels, True)\n"
      ],
      "metadata": {
        "id": "N6rrCwGQhAMo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb11e07b-af94-43ea-adc1-f7f3e32d6487"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Metric    |   Score\n",
            "-------------------\n",
            "Precision |   0.16\n",
            "Recall    |   0.25\n",
            "F1 Score  |   0.20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### WTG1E"
      ],
      "metadata": {
        "id": "N4aLDGzriV55"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loadData = pd.read_csv(\"prompting_without_techniques_guide_one_shot.csv\")\n",
        "true_labels_WTG1E = loadData['True_labels']\n",
        "predicted_labels = loadData['Technique_id']\n",
        "\n",
        "evaluation(true_labels_WTG1E, predicted_labels)\n"
      ],
      "metadata": {
        "id": "zQA4rWWziLYw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c258c4f3-f927-456a-ba77-3cbffd3b330d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Metric    |   Score\n",
            "-------------------\n",
            "Precision |   0.05\n",
            "Recall    |   0.10\n",
            "F1 Score  |   0.07\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### WTG2E"
      ],
      "metadata": {
        "id": "rEZUDADziXI4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loadData = pd.read_csv(\"prompting_without_techniques_guide_two_shot.csv\")\n",
        "true_labels_WTG2E = loadData['True_labels']\n",
        "predicted_labels = loadData['Technique_id']\n",
        "\n",
        "evaluation(true_labels_WTG2E, predicted_labels)\n"
      ],
      "metadata": {
        "id": "YIQDq1rtiNtZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46f70e96-1ef4-4d80-89a7-a40203d20882"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Metric    |   Score\n",
            "-------------------\n",
            "Precision |   0.10\n",
            "Recall    |   0.05\n",
            "F1 Score  |   0.07\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### TGWE"
      ],
      "metadata": {
        "id": "o-wT4dHgiYeK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loadData = pd.read_csv('prompting_with_techniques_guide_zero_shot_False.csv')\n",
        "true_labels_TGWE = loadData['True_labels']\n",
        "predicted_labels = loadData['Without_Prompt_Limit_Without_Competition_Without_Limit_Return']\n",
        "\n",
        "evaluation(true_labels_TGWE, predicted_labels, True)\n",
        "print()\n",
        "\n",
        "\n",
        "predicted_labels = loadData['Without_Prompt_Limit_Without_Competition_With_Limit_Return']\n",
        "evaluation(true_labels_TGWE, predicted_labels, True)\n",
        "print()\n",
        "\n",
        "\n",
        "predicted_labels = loadData['Without_Prompt_Limit_With_Competition_Without_Limit_Return']\n",
        "evaluation(true_labels_TGWE, predicted_labels, True)\n",
        "print()\n",
        "\n",
        "\n",
        "predicted_labels = loadData['Without_Prompt_Limit_With_Competition_With_Limit_Return']\n",
        "evaluation(true_labels_TGWE, predicted_labels, True)"
      ],
      "metadata": {
        "id": "tEyK5479k9JS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0bd0812f-8bae-4e80-b19c-e777d516c352"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Metric    |   Score\n",
            "-------------------\n",
            "Precision |   0.07\n",
            "Recall    |   0.57\n",
            "F1 Score  |   0.13\n",
            "\n",
            "Metric    |   Score\n",
            "-------------------\n",
            "Precision |   0.12\n",
            "Recall    |   0.20\n",
            "F1 Score  |   0.15\n",
            "\n",
            "Metric    |   Score\n",
            "-------------------\n",
            "Precision |   0.21\n",
            "Recall    |   0.39\n",
            "F1 Score  |   0.28\n",
            "\n",
            "Metric    |   Score\n",
            "-------------------\n",
            "Precision |   0.23\n",
            "Recall    |   0.38\n",
            "F1 Score  |   0.29\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### TG1E"
      ],
      "metadata": {
        "id": "QfTWbXljiipv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loadData = pd.read_csv('prompting_with_techniques_guide_one_shot_False.csv')\n",
        "true_labels_TG1E = loadData['True_labels']\n",
        "predicted_labels = loadData['Without_Prompt_Limit_Without_Competition_Without_Limit_Return']\n",
        "\n",
        "evaluation(true_labels_TG1E, predicted_labels, True)\n",
        "print()\n",
        "\n",
        "\n",
        "predicted_labels = loadData['Without_Prompt_Limit_Without_Competition_With_Limit_Return']\n",
        "evaluation(true_labels_TG1E, predicted_labels, True)\n",
        "print()\n",
        "\n",
        "\n",
        "predicted_labels = loadData['Without_Prompt_Limit_With_Competition_Without_Limit_Return']\n",
        "evaluation(true_labels_TG1E, predicted_labels, True)\n",
        "print()\n",
        "\n",
        "\n",
        "predicted_labels = loadData['Without_Prompt_Limit_With_Competition_With_Limit_Return']\n",
        "evaluation(true_labels_TG1E, predicted_labels, True)"
      ],
      "metadata": {
        "id": "E03xuJw3ig8D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e759fcff-a742-4e01-ed89-a0c72ead588f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Metric    |   Score\n",
            "-------------------\n",
            "Precision |   0.07\n",
            "Recall    |   0.57\n",
            "F1 Score  |   0.12\n",
            "\n",
            "Metric    |   Score\n",
            "-------------------\n",
            "Precision |   0.21\n",
            "Recall    |   0.43\n",
            "F1 Score  |   0.29\n",
            "\n",
            "Metric    |   Score\n",
            "-------------------\n",
            "Precision |   0.14\n",
            "Recall    |   0.29\n",
            "F1 Score  |   0.19\n",
            "\n",
            "Metric    |   Score\n",
            "-------------------\n",
            "Precision |   0.14\n",
            "Recall    |   0.29\n",
            "F1 Score  |   0.19\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### TG2E"
      ],
      "metadata": {
        "id": "R7YhblZjij2Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loadData = pd.read_csv('prompting_with_techniques_guide_two_shot_False.csv')\n",
        "true_labels_TG2E = loadData['True_labels']\n",
        "predicted_labels = loadData['Without_Prompt_Limit_Without_Competition_Without_Limit_Return']\n",
        "\n",
        "evaluation(true_labels_TG2E, predicted_labels, True)\n",
        "print()\n",
        "\n",
        "\n",
        "predicted_labels = loadData['Without_Prompt_Limit_Without_Competition_With_Limit_Return']\n",
        "evaluation(true_labels_TG2E, predicted_labels, True)\n",
        "print()\n",
        "\n",
        "\n",
        "predicted_labels = loadData['Without_Prompt_Limit_With_Competition_Without_Limit_Return']\n",
        "evaluation(true_labels_TG2E, predicted_labels, True)\n",
        "print()\n",
        "\n",
        "\n",
        "predicted_labels = loadData['Without_Prompt_Limit_With_Competition_With_Limit_Return']\n",
        "evaluation(true_labels_TG2E, predicted_labels, True)"
      ],
      "metadata": {
        "id": "9riAtGmQihcQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "772cbd26-3210-454c-fd71-dfb51c2b773d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Metric    |   Score\n",
            "-------------------\n",
            "Precision |   0.40\n",
            "Recall    |   0.70\n",
            "F1 Score  |   0.51\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualization Data"
      ],
      "metadata": {
        "id": "60YlFQFyClWB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Graph plot (zero & all without [before and after limit 2 techniques])\n"
      ],
      "metadata": {
        "id": "MqNbMegXCqtO"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TF-fmJrpgV4V"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}