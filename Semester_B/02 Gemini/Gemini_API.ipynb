{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nGCSuqa3AAQr"
      },
      "source": [
        "### Install the Python SDK\n",
        "\n",
        "The Python SDK for the Gemini API, is contained in the [`google-generativeai`](https://pypi.org/project/google-generativeai/) package. Install the dependency using pip:\n",
        "\n",
        "https://colab.research.google.com/github/google/generative-ai-docs/blob/main/site/en/tutorials/python_quickstart.ipynb#scrollTo=G-zBkueElVEO\n",
        "\n",
        "https://ai.google.dev/tutorials/python_quickstart\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "wdah2H_o_4f0"
      },
      "outputs": [],
      "source": [
        "!pip install -q -U google-generativeai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "evA6zTg0AF_y"
      },
      "source": [
        "\n",
        "# This is formatted as code\n",
        "\n",
        "\n",
        "### Import packages"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3gilna-rAHCK"
      },
      "source": [
        "Import the necessary packages."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "YN-Ju3YqAJCS"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import pandas as pd\n",
        "import time\n",
        "import re\n",
        "import csv\n",
        "import concurrent.futures\n",
        "import pathlib\n",
        "import textwrap\n",
        "\n",
        "import google.generativeai as genai\n",
        "\n",
        "from IPython.display import display\n",
        "from IPython.display import Markdown\n",
        "\n",
        "\n",
        "def to_markdown(text):\n",
        "  text = text.replace('â€¢', '  *')\n",
        "  return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))\n",
        "\n",
        "  # Used to securely store your API key\n",
        "from google.colab import userdata"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4WyM5v5IAQiq"
      },
      "source": [
        "### Setup your API key\n",
        "\n",
        "Before you can use the Gemini API, you must first obtain an API key. If you don't already have one, create a key with one click in Google AI Studio.\n",
        "\n",
        "<a class=\"button button-primary\" href=\"https://makersuite.google.com/app/apikey\" target=\"_blank\" rel=\"noopener noreferrer\">Get an API key</a>\n",
        "\n",
        "\n",
        "In Colab, add the key to the secrets manager under the \"ðŸ”‘\" in the left panel. Give it the name `GOOGLE_API_KEY`.\n",
        "\n",
        "Once you have the API key, pass it to the SDK. You can do this in two ways:\n",
        "\n",
        "* Put the key in the `GOOGLE_API_KEY` environment variable (the SDK will automatically pick it up from there).\n",
        "* Pass the key to `genai.configure(api_key=...)`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "5CE2WIa8AbCx"
      },
      "outputs": [],
      "source": [
        "# Or use `os.getenv('GOOGLE_API_KEY')` to fetch an environment variable.\n",
        "GOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')\n",
        "\n",
        "genai.configure(api_key=GOOGLE_API_KEY)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nhh3kIopARlM"
      },
      "source": [
        "## List models\n",
        "\n",
        "Now you're ready to call the Gemini API. Use `list_models` to see the available Gemini models:\n",
        "\n",
        "* `gemini-pro`: optimized for text-only prompts.\n",
        "* `gemini-pro-vision`: optimized for text-and-images prompts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "id": "N-gvKH_DAhT5",
        "outputId": "046d1673-f02f-4ebd-9256-61137bd7f6a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "models/gemini-1.0-pro\n",
            "models/gemini-1.0-pro-001\n",
            "models/gemini-1.0-pro-latest\n",
            "models/gemini-1.0-pro-vision-latest\n",
            "models/gemini-1.5-flash\n",
            "models/gemini-1.5-flash-001\n",
            "models/gemini-1.5-flash-latest\n",
            "models/gemini-1.5-pro\n",
            "models/gemini-1.5-pro-001\n",
            "models/gemini-1.5-pro-latest\n",
            "models/gemini-pro\n",
            "models/gemini-pro-vision\n"
          ]
        }
      ],
      "source": [
        "for m in genai.list_models():\n",
        "  if 'generateContent' in m.supported_generation_methods:\n",
        "    print(m.name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fVQAtLWEAnt7"
      },
      "source": [
        "Note: For detailed information about the available models, including their capabilities and rate limits, see [Gemini models](https://ai.google.dev/models/gemini). There are options for requesting [rate limit increases](https://ai.google.dev/docs/increase_quota). The rate limit for Gemini-Pro models is 60 requests per minute (RPM).\n",
        "\n",
        "The `genai` package also supports the PaLM  family of models, but only the Gemini models support the generic, multimodal capabilities of the `generateContent` method."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8V2PmdVxAtgk"
      },
      "source": [
        "## Generate text from text inputs\n",
        "\n",
        "For text-only prompts, use the `gemini-pro` model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "jO-uiISLAoiD"
      },
      "outputs": [],
      "source": [
        "# Create the model\n",
        "# See https://ai.google.dev/api/python/google/generativeai/GenerativeModel\n",
        "generation_config = {\n",
        "  \"temperature\": 1,\n",
        "  \"top_p\": 0.95,\n",
        "  \"top_k\": 64,\n",
        "  \"max_output_tokens\": 8192,\n",
        "  \"response_mime_type\": \"text/plain\",\n",
        "}\n",
        "safety_settings = [\n",
        "  {\n",
        "    \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
        "    \"threshold\": \"BLOCK_NONE\",\n",
        "  },\n",
        "  {\n",
        "    \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
        "    \"threshold\": \"BLOCK_NONE\",\n",
        "  },\n",
        "  {\n",
        "    \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
        "    \"threshold\": \"BLOCK_NONE\",\n",
        "  },\n",
        "  {\n",
        "    \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
        "    \"threshold\": \"BLOCK_NONE\",\n",
        "  },\n",
        "]\n",
        "\n",
        "model = genai.GenerativeModel(\n",
        "  model_name=\"gemini-1.0-pro\",\n",
        "  safety_settings=safety_settings\n",
        "  #generation_config=generation_config,\n",
        ")\n",
        "\n",
        "\n",
        "#model = genai.GenerativeModel('models/gemini-1.0-pro')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2zOmFWqCBjki"
      },
      "source": [
        "### Data:\n",
        "Our data will be taken from 162 snort rules that have already been manually labeled to techniques from MITRE ATT&CK."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_xfXZdYzBXoU",
        "outputId": "4a0007e6-2c85-410f-ab88-7fdf5ad3c5e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Labeling_IDS_to_MITRE'...\n",
            "remote: Enumerating objects: 351, done.\u001b[K\n",
            "remote: Counting objects: 100% (351/351), done.\u001b[K\n",
            "remote: Compressing objects: 100% (252/252), done.\u001b[K\n",
            "remote: Total 351 (delta 169), reused 267 (delta 86), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (351/351), 7.04 MiB | 12.16 MiB/s, done.\n",
            "Resolving deltas: 100% (169/169), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/trickdeath0/Labeling_IDS_to_MITRE.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kjfmOSZoBs0B",
        "outputId": "e342fbbf-f575-47f4-8ae7-b1ee17ed28b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Sid                                  URL       technique ids  \\\n",
            "0  50094  https://snort.org/rule_docs/1-50094           ['T1187']   \n",
            "1  38563  https://snort.org/rule_docs/1-38563           ['T1056']   \n",
            "2    976    https://snort.org/rule_docs/1-976           ['T1204']   \n",
            "3   1129   https://snort.org/rule_docs/1-1129           ['T1218']   \n",
            "4  27967  https://snort.org/rule_docs/1-27967  ['T1505', 'T1219']   \n",
            "\n",
            "                                                Rule  \n",
            "0  alert tcp any $HTTP_PORTS -> any any ( msg:\"IN...  \n",
            "1  alert tcp $EXTERNAL_NET $HTTP_PORTS -> $HOME_N...  \n",
            "2  alert tcp $EXTERNAL_NET any -> $HTTP_SERVERS $...  \n",
            "3  alert tcp $EXTERNAL_NET any -> $HTTP_SERVERS $...  \n",
            "4  alert tcp $EXTERNAL_NET any -> $HOME_NET $HTTP...  \n",
            "\n",
            "len(data)=300\n"
          ]
        }
      ],
      "source": [
        "data = pd.read_csv('/content/Labeling_IDS_to_MITRE/Semester_B/01 stratification/test_data_fix.csv') # Our experiment\n",
        "print(data.head())\n",
        "rules_list = data['Rule']\n",
        "true_labels = data['technique ids']\n",
        "\n",
        "#print(data['Sid'][0+41])\n",
        "print(f\"\\n{len(data)=}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "GN3E79jbE-3u"
      },
      "outputs": [],
      "source": [
        "def clean_response(text):\n",
        "    text = text.data.replace(\">\", \"\").strip()  # Remove leading \">\", whitespace\n",
        "    try:\n",
        "      text = text.replace(\"```json\", \"\")\n",
        "      text = text.replace(\"```\", \"\")\n",
        "    except:\n",
        "      pass\n",
        "    return text\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Zero Shot (ZS):**\n",
        "At this stage, the LLMs will receive a prompt that does not include the list of techniques from MITRE ATT&CK in order to examine the results of the models based on prior knowledge that has been trained. According to our request, the LLMs will classify the techniques according to the content of the rule."
      ],
      "metadata": {
        "id": "LPrCg0HfHfIW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def ZS(snort_rule):\n",
        "\n",
        "  prompt = f\"\"\"Rule: {snort_rule}\n",
        "  Return a MITRE technique ID (with quotation marks) that related to the rule\"\"\"\n",
        "\n",
        "  message = model.generate_content(prompt)\n",
        "\n",
        "  return message"
      ],
      "metadata": {
        "id": "EfW-gAONHuN0"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VnatnaJWBVxS"
      },
      "source": [
        "# **Prompting without techniques guide and without example (WTGWE):**\n",
        "At this stage, the LLMs will receive a prompt that does not include the list of techniques from MITRE ATT&CK in order to examine the results of the models based on prior knowledge that has been trained. According to our request, the LLMs will classify the techniques according to the content of the rule.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PDsDx3w3hWsg"
      },
      "source": [
        "**Prompt1:**:\n",
        "\n",
        "      prompt = f\"\"\"You are an information security expert. Your task is to label IDS rules for MITRE ATT&CK techniques based on your cybersecurity knowledge. For the task, you are going to get a single Snort IDS rule and you will need to return the most relevant techniques from MITRE ATT&CK that are related to the rule.\n",
        "      Try to search based on keywords and based on the knowledge you have. For each technique include the following information as JSON in this order: 'Sid', 'Technique ID', 'Technique Name', 'Quotes', 'Explanation'.\n",
        "      Note: The value of the citation field should contain quotation marks from the data sets relevant to the mapped technique are the main reason you chose this technique to be correct. The value of the explanation should be your explanation of why you decided to give the technique and how it relates to the rule. The technique ID should be the official MITRE technique ID.\n",
        "      Please don't write anything but the JSON. Rule: {snort_rule}\"\"\"\n",
        "\n",
        "\n",
        "**prompt2:**:\n",
        "\n",
        "      prompt2 = f\"\"\"I'm going to give you a Snort rule. Read the Snort rule carefully, because I'm going to given you a task about it. Here is the Snort rule: <snort_rule>{snort_rule}</snort_rule>\n",
        "\n",
        "      First, find the techniques from MITRE ATT&CK that are most relevant to the Snort rule.\n",
        "\n",
        "      Then, answer the task, for each technique include the following information as JSON in this order: 'Sid', 'Technique ID', 'Technique Name', 'Quotes', 'Explanation'.\n",
        "\n",
        "      Note: The value of the citation field should contain quotation marks from the data sets relevant to the mapped technique are the main reason you chose this technique to be correct. The value of the explanation should be your explanation of why you decided to give the technique and how it relates to the rule. The technique ID should be the official MITRE technique ID.\n",
        "\n",
        "      Thus, the format of your overall response should look like what's shown between the <examples></examples> tags. Make sure to follow the formatting and spacing exactly.\n",
        "\n",
        "\n",
        "      <examples>\n",
        "        [\n",
        "          \"sid\": \"2274\",\n",
        "          \"Technique ID\": \"T1110\",\n",
        "          \"Technique name\": \"Brute Force\",\n",
        "          \"Quotes\": [\n",
        "            \"\\\"PROTOCOL-POP login brute force attempt\\\"\",\n",
        "            \"track by_dst,count 30,seconds 30\"\n",
        "          ],\n",
        "          \"Explanation\": \"The rule is looking for excessive \\\"USER\\\" commands within a short period of time, which are common indicators of brute-force attacks targeting the POP3 service.\"\n",
        "        ]\n",
        "        </examples>\n",
        "\n",
        "        Do not include anything besides write the JSON.\n",
        "        \"\"\"\n",
        "\n",
        "\n",
        "**prompt3:**:\n",
        "\n",
        "        prompt3 = f\"\"\"You work in a company that deals with information security, your role in the company is to label techniques from MITRE ATT&CK to the rules of IDS systems. The labeling between a rule and a technique indicates that the attacker operated with a technique that you found to be suitable for the rule that alerted the IDS system. Now we will test your knowledge labeling IDS rules for MITRE ATT&CK techniques. For your task, you're going to have a single Snort IDS rule and you'll need to label the most relevant techniques from MITRE ATT&CK associated with the rule. From the rule you receive, your labeling should be based on your knowledge and the information found within the 'msg' in the rule received. For each technique you call the rule, include the following information as JSON format in this order: 'Sid', 'Technique ID', 'Technique Name', 'Quotes', 'Explanation'.  Note: The value of the 'Quotes' field should contain quotation marks from the data sets relevant to the mapped technique. The value of the 'Explanation' should be your explanation of why you decided to give the technique and how it relates to the rule. The 'Technique ID' should be the official MITRE technique ID.\n",
        "        Please don't write anything but the JSON. Rule: {snort_rule}\"\"\")\n",
        "\n",
        "\n",
        "**prompt4:**\n",
        "\n",
        "        prompt4 = f'''You are going to receive a Snort rule and your task is to find as many MITRE ATT&CK techniques as possible that are associated with the rule. Note: You should categorize the techniques to 1 or 2. Technique of type 1 is a technique that you can associate with the rule directly based on the rule. Technique of type 2 is a technique that can be associated with the rule indirectly, based on your knowledge and understanding. The categorization value should be the value 1 or 2, based on the explanation given above. The quotes field value should contain quotes from the rules data that are relevant to the technique mapped and they are the main reason you believe the mapping to this technique is correct. The explanationâ€™s value should be your explanation for why you decided to give the technique and how it is associated with the rule. The technique id should be the official MITRE technique id. For each technique include the following information as JSON: sid, Technique id, Technique name, Categorization, Quotes, Explanation. After each rule I will provide you with, answer according to the provided format. Please do not write anything else but the JSON. Rule: {snort_rule}''')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nEo0jmQhA0Kj"
      },
      "outputs": [],
      "source": [
        "def WTGWE(snort_rule):\n",
        "\n",
        "  prompt = f\"\"\"You are an information security expert. Your task is to label IDS rules for MITRE ATT&CK techniques based on your cybersecurity knowledge. For the task, you are going to get a single Snort IDS rule and you will need to return the most relevant techniques from MITRE ATT&CK that are related to the rule.\n",
        "  Try to search based on keywords and based on the knowledge you have. For each technique include the following information as JSON in this order: 'Sid', 'Technique ID', 'Technique Name', 'Quotes', 'Explanation'.\n",
        "  Note: The value of the citation field should contain quotation marks from the data sets relevant to the mapped technique are the main reason you chose this technique to be correct. The value of the explanation should be your explanation of why you decided to give the technique and how it relates to the rule. The technique ID should be the official MITRE technique ID.\n",
        "  Please don't write anything but the JSON. Rule: {snort_rule}\"\"\"\n",
        "\n",
        "  message = model.generate_content(prompt)\n",
        "\n",
        "  return message\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZOeuevpEthmI"
      },
      "source": [
        "# **Prompting without techniques guide and with 1 example (WTG1E):**\n",
        "At this stage, the LLMs will receive a prompt that does not include the list of techniques from MITRE ATT&CK in order to examine the results of the models based on prior knowledge that has been trained. According to our request, the LLMs will classify the techniques according to the content of the rule.\n",
        "\n",
        "In addition, the prompt has one example (one shot)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FL0QJet6tlF5"
      },
      "outputs": [],
      "source": [
        "def WTG1E(snort_rule):\n",
        "\n",
        "  prompt = f\"\"\"Q: You are an information security expert. Your task is to label IDS rules for MITRE ATT&CK techniques based on your cybersecurity knowledge. For the task, you are going to get a single Snort IDS rule and you will need to return the most relevant techniques from MITRE ATT&CK that are related to the rule.\n",
        "    Try to search based on keywords and based on the knowledge you have. For each technique include the following information as JSON in this order: 'Sid', 'Technique ID', 'Technique Name', 'Quotes', 'Explanation'.\n",
        "    Note: The value of the citation field should contain quotation marks from the data sets relevant to the mapped technique are the main reason you chose this technique to be correct. The value of the explanation should be your explanation of why you decided to give the technique and how it relates to the rule. The technique ID should be the official MITRE technique ID.\n",
        "    Please don't write anything but the JSON. Rule: \"alert tcp $EXTERNAL_NET $HTTP_PORTS -> $HOME_NET any ( msg:\"\"MALWARE-CNC Win.Trojan.GateKeylogger fake 404 response\"\"; flow:to_client,established; http_stat_code; content:\"\"200\"\"; http_stat_msg; content:\"\"OK\"\"; pkt_data; content:\"\">404 Not Found<\"\",fast_pattern,nocase; content:\"\" requested URL / was not found \"\"; metadata:impact_flag red,ruleset community; service:http; T1056; classtype:trojan-activity; sid:38563; rev:4; )\"\n",
        "    A: [\n",
        "        \"sid\": \"38563\",\n",
        "        \"Technique ID\": \"T1056\",\n",
        "        \"Technique name\": \"Input Capture\",\n",
        "        \"Quotes\": \"\\\"Input Capture techniques involve intercepting and capturing user input data, such as keystrokes, to obtain sensitive information. The rule indicates the presence of a Trojan (GateKeylogger) that mimics a '404 Not Found' error to disguise its communication with a command and control server, which is a common method used by keyloggers to stealthily capture input data.\\\"\",\n",
        "        \"Explanation\": \"This event is generated when activity relating to malware is detected.\"\n",
        "    ]\n",
        "\n",
        "    Q: You are an information security expert. Your task is to label IDS rules for MITRE ATT&CK techniques based on your cybersecurity knowledge. For the task, you are going to get a single Snort IDS rule and you will need to return the most relevant techniques from MITRE ATT&CK that are related to the rule.\n",
        "    Try to search based on keywords and based on the knowledge you have. For each technique include the following information as JSON in this order: 'Sid', 'Technique ID', 'Technique Name', 'Quotes', 'Explanation'.\n",
        "    Note: The value of the citation field should contain quotation marks from the data sets relevant to the mapped technique are the main reason you chose this technique to be correct. The value of the explanation should be your explanation of why you decided to give the technique and how it relates to the rule. The technique ID should be the official MITRE technique ID.\n",
        "    Please don't write anything but the JSON. Rule: {snort_rule}\n",
        "    A: \"\"\"\n",
        "\n",
        "  message = model.generate_content(prompt)\n",
        "\n",
        "  return message"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kXZc9FsDt6NI"
      },
      "source": [
        "# **Prompting without techniques guide and with 2 example (WTG2E):**\n",
        "At this stage, the LLMs will receive a prompt that does not include the list of techniques from MITRE ATT&CK in order to examine the results of the models based on prior knowledge that has been trained. According to our request, the LLMs will classify the techniques according to the content of the rule.\n",
        "\n",
        "In addition, the prompt has two example (two shot)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PMJZi1pRt-FG"
      },
      "outputs": [],
      "source": [
        "def WTG2E(snort_rule):\n",
        "\n",
        "  prompt = f\"\"\"Q: You are an information security expert. Your task is to label IDS rules for MITRE ATT&CK techniques based on your cybersecurity knowledge. For the task, you are going to get a single Snort IDS rule and you will need to return the most relevant techniques from MITRE ATT&CK that are related to the rule.\n",
        "    Try to search based on keywords and based on the knowledge you have. For each technique include the following information as JSON in this order: 'Sid', 'Technique ID', 'Technique Name', 'Quotes', 'Explanation'.\n",
        "    Note: The value of the citation field should contain quotation marks from the data sets relevant to the mapped technique are the main reason you chose this technique to be correct. The value of the explanation should be your explanation of why you decided to give the technique and how it relates to the rule. The technique ID should be the official MITRE technique ID.\n",
        "    Please don't write anything but the JSON. Rule: \"alert tcp $EXTERNAL_NET $HTTP_PORTS -> $HOME_NET any ( msg:\"\"MALWARE-CNC Win.Trojan.GateKeylogger fake 404 response\"\"; flow:to_client,established; http_stat_code; content:\"\"200\"\"; http_stat_msg; content:\"\"OK\"\"; pkt_data; content:\"\">404 Not Found<\"\",fast_pattern,nocase; content:\"\" requested URL / was not found \"\"; metadata:impact_flag red,ruleset community; service:http; T1056; classtype:trojan-activity; sid:38563; rev:4; )\"\n",
        "    A: [\n",
        "        \"sid\": \"38563\",\n",
        "        \"Technique ID\": \"T1056\",\n",
        "        \"Technique name\": \"Input Capture\",\n",
        "        \"Quotes\": \"\\\"Input Capture techniques involve intercepting and capturing user input data, such as keystrokes, to obtain sensitive information. The rule indicates the presence of a Trojan (GateKeylogger) that mimics a '404 Not Found' error to disguise its communication with a command and control server, which is a common method used by keyloggers to stealthily capture input data.\\\"\",\n",
        "        \"Explanation\": \"This event is generated when activity relating to malware is detected.\"\n",
        "    ]\n",
        "\n",
        "    Q: You are an information security expert. Your task is to label IDS rules for MITRE ATT&CK techniques based on your cybersecurity knowledge. For the task, you are going to get a single Snort IDS rule and you will need to return the most relevant techniques from MITRE ATT&CK that are related to the rule.\n",
        "    Try to search based on keywords and based on the knowledge you have. For each technique include the following information as JSON in this order: 'Sid', 'Technique ID', 'Technique Name', 'Quotes', 'Explanation'.\n",
        "    Note: The value of the citation field should contain quotation marks from the data sets relevant to the mapped technique are the main reason you chose this technique to be correct. The value of the explanation should be your explanation of why you decided to give the technique and how it relates to the rule. The technique ID should be the official MITRE technique ID.\n",
        "    Please don't write anything but the JSON. Rule: \"alert tcp $EXTERNAL_NET $HTTP_PORTS -> $HOME_NET any ( msg:\"\"MALWARE-CNC Win.Trojan.GateKeylogger fake 404 response\"\"; flow:to_client,established; http_stat_code; content:\"\"200\"\"; http_stat_msg; content:\"\"OK\"\"; pkt_data; content:\"\">404 Not Found<\"\",fast_pattern,nocase; content:\"\" requested URL / was not found \"\"; metadata:impact_flag red,ruleset community; service:http; T1056; classtype:trojan-activity; sid:38563; rev:4; )\"\n",
        "    A: [\n",
        "        \"sid\": \"23934\",\n",
        "        \"Technique ID\": \"T1190\",\n",
        "        \"Technique name\": \"Exploit Public-Facing Application\",\n",
        "        \"Quotes\": \"\\\"Exploit Public-Facing Application techniques involve targeting vulnerabilities in externally facing applications to gain unauthorized access or execute arbitrary code. This rule detects an attempted blind SQL injection attack on the Symantec Web Gateway's 'blocked.php' page, which is a common method attackers use to exploit web applications by manipulating SQL queries.\\\"\",\n",
        "        \"Explanation\": \"SQL injection vulnerability in the management console in Symantec Web Gateway 5.0.x before 5.0.3.18 allows remote attackers to execute arbitrary SQL commands via unspecified vectors, related to a \"blind SQL injection\" issue.\"\n",
        "    ]\n",
        "\n",
        "    Q: You are an information security expert. Your task is to label IDS rules for MITRE ATT&CK techniques based on your cybersecurity knowledge. For the task, you are going to get a single Snort IDS rule and you will need to return the most relevant techniques from MITRE ATT&CK that are related to the rule.\n",
        "    Try to search based on keywords and based on the knowledge you have. For each technique include the following information as JSON in this order: 'Sid', 'Technique ID', 'Technique Name', 'Quotes', 'Explanation'.\n",
        "    Note: The value of the citation field should contain quotation marks from the data sets relevant to the mapped technique are the main reason you chose this technique to be correct. The value of the explanation should be your explanation of why you decided to give the technique and how it relates to the rule. The technique ID should be the official MITRE technique ID.\n",
        "    Please don't write anything but the JSON. Rule: {snort_rule}\n",
        "    A: \"\"\"\n",
        "\n",
        "\n",
        "  message = model.generate_content(prompt)\n",
        "\n",
        "  return message"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9BUVU20puL_k"
      },
      "source": [
        "# **Prompting with techniques guide and without example (TGWE):**\n",
        "In the next step, we will provide the LLMs with the list of all the techniques from MITRE ATT&CK, to guarantee that the models are targeted to the present techniques, even the infrequently used ones. Each technique will include the technique number, the name of the technique and its description. The techniques will be provided to the models in the form of batches (due to the memory limit of the models) and after each batch we will ask him to classify the appropriate techniques from the list he received (if exist), finally we will unite the model's answers for each individual rule.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VFWxZ-O8vCKQ"
      },
      "source": [
        "pre colletion data for TG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t8AoOjjWu1Rp"
      },
      "outputs": [],
      "source": [
        "def recursive_enter(path: str, file_list: list = None) -> list:\n",
        "    if file_list is None:\n",
        "        file_list = []\n",
        "\n",
        "    try:\n",
        "        os.chdir(path)  # Change path\n",
        "\n",
        "        items = os.listdir()  # List everything in the directory\n",
        "        for item in items:\n",
        "            full_path = os.path.join(path, item)\n",
        "\n",
        "            if full_path.endswith(\".json\"):\n",
        "                with open(full_path) as f:\n",
        "                    file_list.append(json.load(f))\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "\n",
        "    return file_list\n",
        "\n",
        "tacticFolder = \"/content/Labeling_IDS_to_MITRE/Semester_A/Extract data from MITRE ATTACK/techniques_split\"\n",
        "file_list = []\n",
        "MITRE_Technique = recursive_enter(tacticFolder, file_list)\n",
        "print(len(MITRE_Technique))\n",
        "os.chdir(\"/content/\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RMit2X0DvIV0"
      },
      "outputs": [],
      "source": [
        "def TGWE(snort_rule, techniques):\n",
        "\n",
        "  prePrompt = f\"\"\"You are an information security expert. Now I will provide you information about techniques from MITRE ATT&CK, you will use the information for a task you will receive later. Do not reply to the information you receive.\"\"\"\n",
        "\n",
        "  dataPrompt = f\"The information:\\n {str(techniques)}\"\n",
        "\n",
        "  response_data = f\"\"\"Your task is to label IDS rules for MITRE ATT&CK techniques based on the information I have provided you. For the task, you are going to get a single Snort IDS rule and you will need to return the most relevant techniques associated with the rule from the information I provided you only.\n",
        "   Note 1: There is not necessarily a suitable technique in the information, return a technique if and only if it has an unambiguous relationship to the provided rule, if not return an empty JSON. For each technique include the following information as JSON in this order: 'Sid', 'Technique ID', 'Technique Name', 'Quotes', 'Explanation'.\n",
        "   Note 2: The value of the citation field should contain quotation marks from the data sets relevant to the mapped technique are the main reason you chose this technique to be correct. The value of the explanation should be your explanation of why you decided to give the technique and how it relates to the rule. The technique ID should be the official MITRE technique ID.\n",
        "   Please don't write anything but the JSON. Rule: {snort_rule}\"\"\"\n",
        "\n",
        "  tg_data_list = [prePrompt, dataPrompt, response_data]\n",
        "\n",
        "  try:\n",
        "    response = model.generate_content(tg_data_list)\n",
        "    #print(response.parts)\n",
        "  except:\n",
        "    #print(response.parts)\n",
        "    response = model.generate_content(\"Return empty JSON {}\")\n",
        "  finally:\n",
        "    return response\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U8gJFCcpvinU"
      },
      "source": [
        "# **Prompting with techniques guide and with 1 example (TG1E):**\n",
        "In the next step, we will provide the LLMs with the list of all the techniques from MITRE ATT&CK, to guarantee that the models are targeted to the present techniques, even the infrequently used ones. Each technique will include the technique number, the name of the technique and its description. The techniques will be provided to the models in the form of batches (due to the memory limit of the models) and after each batch we will ask him to classify the appropriate techniques from the list he received (if exist), finally we will unite the model's answers for each individual rule.\n",
        "\n",
        "In addition, the prompt has one example (one shot)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jFnofVLPvlDy"
      },
      "outputs": [],
      "source": [
        "def TG1E(snort_rule, techniques):\n",
        "\n",
        "  prePrompt = f\"\"\"You are an information security expert. Now I will provide you information about techniques from MITRE ATT&CK, you will use the information for a task you will receive later. Do not reply to the information you receive.\"\"\"\n",
        "\n",
        "  dataPrompt = f\"The information:\\n {str(techniques)}\"\n",
        "\n",
        "  response_data = f\"\"\"Q: You are an information security expert. Your task is to label IDS rules for MITRE ATT&CK techniques based on your cybersecurity knowledge. For the task, you are going to get a single Snort IDS rule and you will need to return the most relevant techniques from MITRE ATT&CK that are related to the rule.\n",
        "    Try to search based on keywords and based on the knowledge you have. For each technique include the following information as JSON in this order: 'Sid', 'Technique ID', 'Technique Name', 'Quotes', 'Explanation'.\n",
        "    Note: The value of the citation field should contain quotation marks from the data sets relevant to the mapped technique are the main reason you chose this technique to be correct. The value of the explanation should be your explanation of why you decided to give the technique and how it relates to the rule. The technique ID should be the official MITRE technique ID.\n",
        "    Please don't write anything but the JSON. Rule: \"alert tcp $EXTERNAL_NET $HTTP_PORTS -> $HOME_NET any ( msg:\"\"MALWARE-CNC Win.Trojan.GateKeylogger fake 404 response\"\"; flow:to_client,established; http_stat_code; content:\"\"200\"\"; http_stat_msg; content:\"\"OK\"\"; pkt_data; content:\"\">404 Not Found<\"\",fast_pattern,nocase; content:\"\" requested URL / was not found \"\"; metadata:impact_flag red,ruleset community; service:http; T1056; classtype:trojan-activity; sid:38563; rev:4; )\"\n",
        "    A: [\n",
        "        \"sid\": \"38563\",\n",
        "        \"Technique ID\": \"T1056\",\n",
        "        \"Technique name\": \"Input Capture\",\n",
        "        \"Quotes\": \"\\\"Input Capture techniques involve intercepting and capturing user input data, such as keystrokes, to obtain sensitive information. The rule indicates the presence of a Trojan (GateKeylogger) that mimics a '404 Not Found' error to disguise its communication with a command and control server, which is a common method used by keyloggers to stealthily capture input data.\\\"\",\n",
        "        \"Explanation\": \"This event is generated when activity relating to malware is detected.\"\n",
        "    ]\n",
        "\n",
        "    Q: You are an information security expert. Your task is to label IDS rules for MITRE ATT&CK techniques based on your cybersecurity knowledge. For the task, you are going to get a single Snort IDS rule and you will need to return the most relevant techniques from MITRE ATT&CK that are related to the rule.\n",
        "    Try to search based on keywords and based on the knowledge you have. For each technique include the following information as JSON in this order: 'Sid', 'Technique ID', 'Technique Name', 'Quotes', 'Explanation'.\n",
        "    Note: The value of the citation field should contain quotation marks from the data sets relevant to the mapped technique are the main reason you chose this technique to be correct. The value of the explanation should be your explanation of why you decided to give the technique and how it relates to the rule. The technique ID should be the official MITRE technique ID.\n",
        "    Please don't write anything but the JSON. Rule: {snort_rule}\n",
        "    A: \"\"\"\n",
        "\n",
        "  tg_data_list = [prePrompt, dataPrompt, response_data]\n",
        "\n",
        "  try:\n",
        "    response = model.generate_content(tg_data_list)\n",
        "    #print(response.parts)\n",
        "  except:\n",
        "    #print(response.parts)\n",
        "    response = model.generate_content(\"Return empty JSON {}\")\n",
        "  finally:\n",
        "    return response\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RatZWbuyvrKg"
      },
      "source": [
        "# **Prompting with techniques guide and with 2 example (TG2E):**\n",
        "In the next step, we will provide the LLMs with the list of all the techniques from MITRE ATT&CK, to guarantee that the models are targeted to the present techniques, even the infrequently used ones. Each technique will include the technique number, the name of the technique and its description. The techniques will be provided to the models in the form of batches (due to the memory limit of the models) and after each batch we will ask him to classify the appropriate techniques from the list he received (if exist), finally we will unite the model's answers for each individual rule.\n",
        "\n",
        "In addition, the prompt has two example (two shot)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gowEZfU7vya-"
      },
      "outputs": [],
      "source": [
        "def TG2E(snort_rule, techniques):\n",
        "\n",
        "  prePrompt = f\"\"\"You are an information security expert. Now I will provide you information about techniques from MITRE ATT&CK, you will use the information for a task you will receive later. Do not reply to the information you receive.\"\"\"\n",
        "\n",
        "  dataPrompt = f\"The information:\\n {str(techniques)}\"\n",
        "\n",
        "  response_data = f\"\"\"Q: You are an information security expert. Your task is to label IDS rules for MITRE ATT&CK techniques based on your cybersecurity knowledge. For the task, you are going to get a single Snort IDS rule and you will need to return the most relevant techniques from MITRE ATT&CK that are related to the rule.\n",
        "    Try to search based on keywords and based on the knowledge you have. For each technique include the following information as JSON in this order: 'Sid', 'Technique ID', 'Technique Name', 'Quotes', 'Explanation'.\n",
        "    Note: The value of the citation field should contain quotation marks from the data sets relevant to the mapped technique are the main reason you chose this technique to be correct. The value of the explanation should be your explanation of why you decided to give the technique and how it relates to the rule. The technique ID should be the official MITRE technique ID.\n",
        "    Please don't write anything but the JSON. Rule: \"alert tcp $EXTERNAL_NET $HTTP_PORTS -> $HOME_NET any ( msg:\"\"MALWARE-CNC Win.Trojan.GateKeylogger fake 404 response\"\"; flow:to_client,established; http_stat_code; content:\"\"200\"\"; http_stat_msg; content:\"\"OK\"\"; pkt_data; content:\"\">404 Not Found<\"\",fast_pattern,nocase; content:\"\" requested URL / was not found \"\"; metadata:impact_flag red,ruleset community; service:http; T1056; classtype:trojan-activity; sid:38563; rev:4; )\"\n",
        "    A: [\n",
        "        \"sid\": \"38563\",\n",
        "        \"Technique ID\": \"T1056\",\n",
        "        \"Technique name\": \"Input Capture\",\n",
        "        \"Quotes\": \"\\\"Input Capture techniques involve intercepting and capturing user input data, such as keystrokes, to obtain sensitive information. The rule indicates the presence of a Trojan (GateKeylogger) that mimics a '404 Not Found' error to disguise its communication with a command and control server, which is a common method used by keyloggers to stealthily capture input data.\\\"\",\n",
        "        \"Explanation\": \"This event is generated when activity relating to malware is detected.\"\n",
        "    ]\n",
        "\n",
        "    Q: You are an information security expert. Your task is to label IDS rules for MITRE ATT&CK techniques based on your cybersecurity knowledge. For the task, you are going to get a single Snort IDS rule and you will need to return the most relevant techniques from MITRE ATT&CK that are related to the rule.\n",
        "    Try to search based on keywords and based on the knowledge you have. For each technique include the following information as JSON in this order: 'Sid', 'Technique ID', 'Technique Name', 'Quotes', 'Explanation'.\n",
        "    Note: The value of the citation field should contain quotation marks from the data sets relevant to the mapped technique are the main reason you chose this technique to be correct. The value of the explanation should be your explanation of why you decided to give the technique and how it relates to the rule. The technique ID should be the official MITRE technique ID.\n",
        "    Please don't write anything but the JSON. Rule: \"alert tcp $EXTERNAL_NET $HTTP_PORTS -> $HOME_NET any ( msg:\"\"MALWARE-CNC Win.Trojan.GateKeylogger fake 404 response\"\"; flow:to_client,established; http_stat_code; content:\"\"200\"\"; http_stat_msg; content:\"\"OK\"\"; pkt_data; content:\"\">404 Not Found<\"\",fast_pattern,nocase; content:\"\" requested URL / was not found \"\"; metadata:impact_flag red,ruleset community; service:http; T1056; classtype:trojan-activity; sid:38563; rev:4; )\"\n",
        "    A: [\n",
        "        \"sid\": \"23934\",\n",
        "        \"Technique ID\": \"T1190\",\n",
        "        \"Technique name\": \"Exploit Public-Facing Application\",\n",
        "        \"Quotes\": \"\\\"Exploit Public-Facing Application techniques involve targeting vulnerabilities in externally facing applications to gain unauthorized access or execute arbitrary code. This rule detects an attempted blind SQL injection attack on the Symantec Web Gateway's 'blocked.php' page, which is a common method attackers use to exploit web applications by manipulating SQL queries.\\\"\",\n",
        "        \"Explanation\": \"SQL injection vulnerability in the management console in Symantec Web Gateway 5.0.x before 5.0.3.18 allows remote attackers to execute arbitrary SQL commands via unspecified vectors, related to a \"blind SQL injection\" issue.\"\n",
        "    ]\n",
        "\n",
        "    Q: You are an information security expert. Your task is to label IDS rules for MITRE ATT&CK techniques based on your cybersecurity knowledge. For the task, you are going to get a single Snort IDS rule and you will need to return the most relevant techniques from MITRE ATT&CK that are related to the rule.\n",
        "    Try to search based on keywords and based on the knowledge you have. For each technique include the following information as JSON in this order: 'Sid', 'Technique ID', 'Technique Name', 'Quotes', 'Explanation'.\n",
        "    Note: The value of the citation field should contain quotation marks from the data sets relevant to the mapped technique are the main reason you chose this technique to be correct. The value of the explanation should be your explanation of why you decided to give the technique and how it relates to the rule. The technique ID should be the official MITRE technique ID.\n",
        "    Please don't write anything but the JSON. Rule: {snort_rule}\n",
        "    A: \"\"\"\n",
        "\n",
        "  tg_data_list = [prePrompt, dataPrompt, response_data]\n",
        "\n",
        "  try:\n",
        "    response = model.generate_content(tg_data_list)\n",
        "    #print(response.parts)\n",
        "  except:\n",
        "    #print(response.parts)\n",
        "    response = model.generate_content(\"Return empty JSON {}\")\n",
        "  finally:\n",
        "    return response\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3WNMlVQ4v3Yy"
      },
      "source": [
        "# Write to csv"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def write_csv_ZS(filename, rule_dict):\n",
        "  # Define the field names\n",
        "  field_names = [\"Technique_id\", \"True_labels\"]\n",
        "\n",
        "  # Open the CSV file in write mode (truncating any existing content)\n",
        "  with open(filename, \"w\", newline=\"\") as csvfile: # \"prompting_without_techniques_guide.csv\"\n",
        "      # Create a DictWriter object with the specified field names\n",
        "      writer = csv.DictWriter(csvfile, fieldnames=field_names)\n",
        "\n",
        "      # Write the header row\n",
        "      writer.writeheader()\n",
        "\n",
        "      # Extract relevant data from each item and write it as a dictionary\n",
        "      counter = 0\n",
        "      for key, value in rule_dict.items():\n",
        "        text = clean_response(value)\n",
        "        technique_ids = []\n",
        "\n",
        "        if \"'Sid\" in text:\n",
        "          # Define a regex pattern to switch single quotes to double quotes\n",
        "          pattern = re.compile(r\"((^|\\s)'((?:[^'\\\\]|\\\\.)*)'(?=[\\s.,:;!?)]))|(:\\s*'((?:[^'\\\\]|\\\\.)+)')\")\n",
        "          # Switch single quotes to double quotes\n",
        "          text = pattern.sub(lambda x: x.group().replace(\"'\", '\"'), text)\n",
        "\n",
        "          pattern = re.compile(r'\"\\S+\"[\\s\\.]|\\s\"[\\w\\s]*\"\\s')\n",
        "          text = re.sub(pattern, \"\", text)\n",
        "\n",
        "        # Extracting \"TXXXX\" numbers using regular expression\n",
        "        technique_ids = re.findall(r'[\\'\\\"](T\\d+(?:\\.\\d+)?)', text)\n",
        "\n",
        "        # Extracting \"Sid\"\n",
        "        match = re.search(r'[\\'\\\"][s|S]id[\\'\\\"]: [\\'\\\"](\\d+)[\\'\\\"]', text)\n",
        "        if match:\n",
        "            sid_number = match.group(1)\n",
        "\n",
        "\n",
        "        # Assuming each item has all necessary fields:\n",
        "        insertRow = {\n",
        "            \"Technique_id\": technique_ids,  # Handle potential absence\n",
        "            \"True_labels\": true_labels[counter],\n",
        "        }\n",
        "        writer.writerow(insertRow)\n",
        "        counter += 1\n"
      ],
      "metadata": {
        "id": "bRlQaQNLTFBi"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vHHFi90pwAxB"
      },
      "source": [
        "Write without techniques guide"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "_U86tigTwD32"
      },
      "outputs": [],
      "source": [
        "def write_csv_WTG(filename, rule_dict):\n",
        "  # Define the field names\n",
        "  field_names = [\"Sid\", \"Response\", \"Technique_id\", \"True_labels\"]\n",
        "\n",
        "  # Open the CSV file in write mode (truncating any existing content)\n",
        "  with open(filename, \"w\", newline=\"\") as csvfile: # \"prompting_without_techniques_guide.csv\"\n",
        "      # Create a DictWriter object with the specified field names\n",
        "      writer = csv.DictWriter(csvfile, fieldnames=field_names)\n",
        "\n",
        "      # Write the header row\n",
        "      writer.writeheader()\n",
        "\n",
        "      # Extract relevant data from each item and write it as a dictionary\n",
        "      counter = 0\n",
        "      for key, value in rule_dict.items():\n",
        "        text = clean_response(value)\n",
        "        technique_ids = []\n",
        "\n",
        "        if \"'Sid\" in text:\n",
        "          # Define a regex pattern to switch single quotes to double quotes\n",
        "          pattern = re.compile(r\"((^|\\s)'((?:[^'\\\\]|\\\\.)*)'(?=[\\s.,:;!?)]))|(:\\s*'((?:[^'\\\\]|\\\\.)+)')\")\n",
        "          # Switch single quotes to double quotes\n",
        "          text = pattern.sub(lambda x: x.group().replace(\"'\", '\"'), text)\n",
        "\n",
        "          pattern = re.compile(r'\"\\S+\"[\\s\\.]|\\s\"[\\w\\s]*\"\\s')\n",
        "          text = re.sub(pattern, \"\", text)\n",
        "\n",
        "        # Extracting \"TXXXX\" numbers using regular expression\n",
        "        technique_ids = re.findall(r'[\\'\\\"](T\\d+(?:\\.\\d+)?)', text)\n",
        "\n",
        "        # Extracting \"Sid\"\n",
        "        match = re.search(r'[\\'\\\"][s|S]id[\\'\\\"]: [\\'\\\"](\\d+)[\\'\\\"]', text)\n",
        "        if match:\n",
        "            sid_number = match.group(1)\n",
        "\n",
        "\n",
        "        # Assuming each item has all necessary fields:\n",
        "        insertRow = {\n",
        "            \"Sid\": sid_number,\n",
        "            \"Response\": text,\n",
        "            \"Technique_id\": technique_ids,  # Handle potential absence\n",
        "            \"True_labels\": true_labels[counter],\n",
        "        }\n",
        "        writer.writerow(insertRow)\n",
        "        counter += 1\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pX7QiV0HwHZ8"
      },
      "source": [
        "Write with techniques guide"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rO-Aa_bLwJLz"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "import re\n",
        "\n",
        "headersCSV_TG = [\"Sid\", \"Response\", \"Technique_id\", \"True_labels\"]\n",
        "\n",
        "def init_file(fileName):\n",
        "  # Initial write to csv with header\n",
        "  with open(fileName, 'w', newline='') as csvfile: # 'prompting_with_techniques_guide.csv'\n",
        "      writer = csv.DictWriter(csvfile, fieldnames=headersCSV_TG)\n",
        "      writer.writeheader()\n",
        "\n",
        "def appendToCSV(rows_data, counter, fileName) -> None:\n",
        "    '''\n",
        "    rows_data -> {213: [<IPython.core.display.Markdown object>, <IPython.core.display.Markdown object>, ...]}\n",
        "    '''\n",
        "    # Open the CSV file in append mode to add new rows\n",
        "    with open(fileName, 'a', newline='') as csvfile:\n",
        "        writer = csv.DictWriter(csvfile, fieldnames=headersCSV_TG)\n",
        "\n",
        "        # Loop through each row and write data\n",
        "        for row, value in rows_data.items():\n",
        "            technique_ids = []\n",
        "            response_text = \"\"\n",
        "            for i in value:\n",
        "                text = clean_response(i)\n",
        "                response_text += text\n",
        "                #print(text)\n",
        "\n",
        "                try:\n",
        "                    # Extracting \"TXXXX\" numbers using regular expression\n",
        "                    technique_ids.extend(re.findall(r': [\\'\\\"](T\\d+(?:\\.\\d+)?)', text))\n",
        "                except Exception as e:\n",
        "                    print(f\"Error extracting technique IDs: {e}\")\n",
        "\n",
        "            insertRow = {\n",
        "                \"Sid\": row,\n",
        "                \"Response\": response_text,\n",
        "                \"Technique_id\": technique_ids,\n",
        "                \"True_labels\": true_labels[counter]\n",
        "            }\n",
        "\n",
        "            # Write the row to the CSV file\n",
        "            writer.writerow(insertRow)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Gh8RQNSwQFR"
      },
      "source": [
        "# WTG - Generic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "ihiec48Hwa6l"
      },
      "outputs": [],
      "source": [
        "def WTG(functionName, rules_list):\n",
        "  rule_dict = {}\n",
        "  max_retries = 3  # Maximum number of retries\n",
        "\n",
        "  for index, rule in enumerate(rules_list):\n",
        "      retries = 0\n",
        "      time.sleep(4)\n",
        "      print(f\"------------- {index} -------------\")\n",
        "      while retries < max_retries:\n",
        "          try:\n",
        "              res = functionName(rule)\n",
        "              text = res.text\n",
        "              # Check if the text contains the desired pattern\n",
        "              t_numbers = re.findall(r'[\\'\\\"](T\\d+(?:\\.\\d+)?)', text)\n",
        "              if t_numbers:  # If the pattern is found\n",
        "                  rule_dict[data['Sid'][index]] = to_markdown(text)\n",
        "                  break  # Break out of the retry loop if successful\n",
        "              else:\n",
        "                  print(\"Desired pattern not found in the text. Retrying...\")\n",
        "                  retries += 1\n",
        "                  time.sleep(1)  # Wait for a short duration before retrying\n",
        "          except Exception as e:\n",
        "              print(f\"An error occurred: {e}\")\n",
        "              retries += 1\n",
        "              if retries < max_retries:\n",
        "                  print(f\"Retrying... ({retries}/{max_retries})\")\n",
        "                  time.sleep(1)  # Wait for a short duration before retrying\n",
        "              else:\n",
        "                  print(\"Max retries reached. Unable to process this rule.\")\n",
        "\n",
        "\n",
        "  # If sending fails, attempt to send again\n",
        "  try:\n",
        "      # Code to send data\n",
        "      pass\n",
        "  except Exception as e:\n",
        "      print(f\"Sending failed: {e}\")\n",
        "      # Retry sending here\n",
        "\n",
        "  return rule_dict\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3n0NFhMTwe3i"
      },
      "source": [
        "# TG - Generic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cKMf8juVwjuh"
      },
      "outputs": [],
      "source": [
        "def tg_split_data(functionName, rules_list_index, index, fileName):\n",
        "\n",
        "  for rule in rules_list_index:\n",
        "    print(f\"index {index} \\t Sid: {data['Sid'][index]}\")\n",
        "\n",
        "    tg_dict = {}\n",
        "    count = 0 #####\n",
        "    for batch in MITRE_Technique: # 11 files\n",
        "      time.sleep(2)\n",
        "      res = tg(rule, batch)\n",
        "      sid = data['Sid'][index]\n",
        "      if sid not in tg_dict:\n",
        "        tg_dict[sid] = []\n",
        "        tg_dict[sid].append(to_markdown(res.text))\n",
        "      else:\n",
        "        #print(res.text)\n",
        "        try:\n",
        "          tg_dict[sid].append(to_markdown(res.text))\n",
        "        except:\n",
        "          tg_dict[sid].append(to_markdown(\"{}\"))\n",
        "      print(f\"~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~{count}~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\") #####\n",
        "      #print(to_markdown(res.text))\n",
        "      count += 1 #######\n",
        "\n",
        "    # Write to csv\n",
        "    appendToCSV(tg_dict, index)\n",
        "    index += 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l2t6CNpjwnRh"
      },
      "source": [
        "# Run Experiments"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bnw-E-pGwqnE"
      },
      "source": [
        "without data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "Ikg69ozPwsnL"
      },
      "outputs": [],
      "source": [
        " # Without Example Without Techniuqes Guide\n",
        "# rule_dict_ZS = WTG(ZS, rules_list)\n",
        "write_csv_ZS(\"zero_shot.csv\", rule_dict_ZS)\n",
        "\n",
        "\n",
        "#  # Without Example Without Techniuqes Guide\n",
        "# rule_dict_WTG = WTG(WTGWE, rules_list)\n",
        "# write_csv_WTG(\"prompting_without_techniques_guide_zero_shot.csv\", rule_dict_WTG)\n",
        "\n",
        "\n",
        "#  # With 1 Example Without Techniuqes Guide\n",
        "# rule_dict_WTG1E = WTG(WTG1E, rules_list)\n",
        "# write_csv_WTG(\"prompting_without_techniques_guide_one_shot.csv\", rule_dict_WTG1E)\n",
        "\n",
        "\n",
        "#  # With 2 Example Without Techniuqes Guide\n",
        "# rule_dict_WTG2E = WTG(WTG2E, rules_list)\n",
        "# write_csv_WTG(\"prompting_without_techniques_guide_two_shot.csv\", rule_dict_WTG2E)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hA9Re3VUwydO"
      },
      "source": [
        "with data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VXVn219hwz9m"
      },
      "outputs": [],
      "source": [
        " # Without Example With Techniuqes Guide\n",
        "init_file('prompting_with_techniques_guide_zero_shot.csv')\n",
        "\n",
        "rule_dict_TGWE_01 = rules_list[:100] # index 0-99\n",
        "tg_split_data(rule_dict_TGWE_01, 0)\n",
        "\n",
        "# rule_dict_TGWE_02 = rules_list[100:200] # index 100-199\n",
        "# tg_split_data(rule_dict_TGWE_02, 100)\n",
        "\n",
        "# rule_dict_TGWE_03 = rules_list[200:] # index 200-299\n",
        "# tg_split_data(rule_dict_TGWE_03, 200)\n",
        "\n",
        "\n",
        "\n",
        "  # With 1 Example With Techniuqes Guide\n",
        "init_file('prompting_with_techniques_guide_one_shot.csv')\n",
        "\n",
        "rule_dict_TG1E_01 = rules_list[:100] # index 0-99\n",
        "tg_split_data(rule_dict_TG1E_01, 0)\n",
        "\n",
        "# rule_dict_TG1E_02 = rules_list[100:200] # index 100-199\n",
        "# tg_split_data(rule_dict_TG1E_02, 100)\n",
        "\n",
        "# rule_dict_TG1E_03 = rules_list[200:] # index 200-299\n",
        "# tg_split_data(rule_dict_TG1E_03, 200)\n",
        "\n",
        "\n",
        "\n",
        " # With 2 Example With Techniuqes Guide\n",
        "init_file('prompting_with_techniques_guide_two_shot.csv')\n",
        "\n",
        "rule_dict_TG2E_01 = rules_list[:100] # index 0-99\n",
        "tg_split_data(rule_dict_TG2E_01, 0)\n",
        "\n",
        "# rule_dict_TG2E_02 = rules_list[100:200] # index 100-199\n",
        "# tg_split_data(rule_dict_TG2E_02, 100)\n",
        "\n",
        "# rule_dict_TG2E_03 = rules_list[200:] # index 200-299\n",
        "# tg_split_data(rule_dict_TG2E_03, 200)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# rule_dict_WTG = rules_list[:5] # index 0-1\n",
        "# #rules_list2 = rules_list[2:4] # index 2-3\n",
        "\n",
        "\n",
        "# tg_split_data(TGWE, rules_list_index, index, fileName)\n",
        "\n",
        "\n",
        "# tg_split_data(TGWE, rules_list1, 0)\n",
        "# # tg_split_data(rules_list2, 2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xHcO72xYunRn"
      },
      "source": [
        "# Evaluation\n",
        "\n",
        "\n",
        "*   Persicion\n",
        "*   Recall\n",
        "*   F-1\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "BtUPUMRCum1W"
      },
      "outputs": [],
      "source": [
        "import ast\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "def evaluation(true_labels, predicted_labels):\n",
        "\n",
        "  recall = []\n",
        "  precision = []\n",
        "  f1 = []\n",
        "\n",
        "\n",
        "  for i in range(len(true_labels)):\n",
        "    trueList = ast.literal_eval(true_labels[i])\n",
        "    predList = ast.literal_eval(predicted_labels[i])\n",
        "    # Extract only the 'TXXXX' part from each string in the list\n",
        "    predList = [item.split('.')[0] if '.' in item else item for item in predList]\n",
        "    intersection = set(trueList).intersection(set(predList))\n",
        "    #print(list(intersection))\n",
        "\n",
        "    if (len(predList) != 0):\n",
        "      recall.append(len(intersection) / len(set(trueList)))\n",
        "      precision.append(len(intersection) / len(set(predList)))\n",
        "      try:\n",
        "        f1.append((2 * precision[i] * recall[i]) / (recall[i] + precision[i]))\n",
        "      except:\n",
        "        f1.append(0)\n",
        "\n",
        "  # Avg.\n",
        "  average_recall = sum(recall) / len(recall)\n",
        "  average_precision = sum(precision) / len(precision)\n",
        "  average_f1 = (2 * average_recall * average_precision) / (average_recall + average_precision)\n",
        "\n",
        "  print(\"Metric    |   Score\")\n",
        "  print(\"-------------------\")\n",
        "  print(f\"Precision |   {average_precision:.2f}\")\n",
        "  print(f\"Recall    |   {average_recall:.2f}\")\n",
        "  print(f\"F1 Score  |   {average_f1:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ZS"
      ],
      "metadata": {
        "id": "SBKhM4XYTo_S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loadData = pd.read_csv(\"zero_shot.csv\")\n",
        "true_labels_ZS = loadData['True_labels']\n",
        "predicted_labels = loadData['Technique_id']\n",
        "\n",
        "evaluation(true_labels_ZS, predicted_labels)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S7t--Z1YTqZR",
        "outputId": "4d489325-1813-47ab-d734-df373cf2e5a6"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Metric    |   Score\n",
            "-------------------\n",
            "Precision |   0.08\n",
            "Recall    |   0.08\n",
            "F1 Score  |   0.08\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_oq8JCf8w81I"
      },
      "source": [
        "#### WTGWE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "v8LoB7cMyIGQ",
        "outputId": "8e92475e-674c-4cab-a0db-0758518fb81e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Metric    |   Score\n",
            "-------------------\n",
            "Precision |   0.09\n",
            "Recall    |   0.10\n",
            "F1 Score  |   0.09\n"
          ]
        }
      ],
      "source": [
        "loadData = pd.read_csv(\"prompting_without_techniques_guide_zero_shot.csv\")\n",
        "true_labels_WTGWE = loadData['True_labels']\n",
        "predicted_labels = loadData['Technique_id']\n",
        "\n",
        "evaluation(true_labels_WTGWE, predicted_labels)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mz_kXPetxHPb"
      },
      "source": [
        "#### WTG1E"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tuN4ctDmxIHj"
      },
      "outputs": [],
      "source": [
        "loadData = pd.read_csv(\"prompting_without_techniques_guide_one_shot.csv\")\n",
        "true_labels_WTG1E = loadData['True_labels']\n",
        "predicted_labels = loadData['Technique_id']\n",
        "\n",
        "evaluation(true_labels_WTG1E, predicted_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TFB6RCETxKmL"
      },
      "source": [
        "#### WTG2E"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D0BL_-cLxNcZ"
      },
      "outputs": [],
      "source": [
        "loadData = pd.read_csv(\"prompting_without_techniques_guide_two_shot.csv\")\n",
        "true_labels_WTG2E = loadData['True_labels']\n",
        "predicted_labels = loadData['Technique_id']\n",
        "\n",
        "evaluation(true_labels_WTG2E, predicted_labels)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Fe762c9xYMO"
      },
      "source": [
        "#### TGWE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y1K4MuFBxZdT"
      },
      "outputs": [],
      "source": [
        "loadData = pd.read_csv('prompting_with_techniques_guide_zero_shot.csv')\n",
        "true_labels_TGWE = loadData['True_labels']\n",
        "predicted_labels = loadData['Technique_id']\n",
        "\n",
        "evaluation(true_labels_TGWE, predicted_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GKZfq1Gdxdw2"
      },
      "source": [
        "#### TG1E"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B1iX7DBjxfr3"
      },
      "outputs": [],
      "source": [
        "loadData = pd.read_csv('prompting_with_techniques_guide_one_shot.csv')\n",
        "true_labels_TG1E = loadData['True_labels']\n",
        "predicted_labels = loadData['Technique_id']\n",
        "\n",
        "evaluation(true_labels_TG1E, predicted_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1pUT9_NGxkX2"
      },
      "source": [
        "#### TG2E"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YUJec72HxlEJ"
      },
      "outputs": [],
      "source": [
        "loadData = pd.read_csv('prompting_with_techniques_guide_two_shot.csv')\n",
        "true_labels_TG2E = loadData['True_labels']\n",
        "predicted_labels = loadData['Technique_id']\n",
        "\n",
        "evaluation(true_labels_TG2E, predicted_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualization Data"
      ],
      "metadata": {
        "id": "R51ul1wd-q5X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tabulate\n",
        "import pandas as pd\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from tabulate import tabulate\n",
        "\n",
        "\n",
        "# List of file names\n",
        "file_names = [\n",
        "    'Nir_Dataset_162_without_techniques.csv', 'Nir_Dataset_162_with_techniques.csv', # Nir data\n",
        "    'Our_Dataset_300_without_techniques_and_zero_shot.csv', 'Our_Dataset_300_with_techniques_zero_shot.csv', # Zero shot\n",
        "    'Our_Dataset_300_without_techniques_and_one_shot.csv', # One shot\n",
        "    'Our_Dataset_300_without_techniques_and_two_shot.csv', 'Our_Dataset_300_with_techniques_two_shot.csv'      # Two shot\n",
        "]\n",
        "\n",
        "# Load all files into a dictionary of DataFrames\n",
        "data_frames = {file: pd.read_csv(file) for file in file_names}\n",
        "\n",
        "# # Optionally, display the first few rows of each DataFrame\n",
        "# for name, df in data_frames.items():\n",
        "#     print(f\"\\n{name}:\\n\", df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zKq1SM9a-yV4",
        "outputId": "57376fc4-366f-4a88-ccdd-b4da7ed94fa9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (0.9.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Loop over each file, load the data, and evaluate\n",
        "for file in file_names:\n",
        "    try:\n",
        "        # Load the data\n",
        "        loadData = pd.read_csv(file)\n",
        "\n",
        "        # Extract the true and predicted labels\n",
        "        true_labels = loadData['True_labels']\n",
        "        predicted_labels = loadData['Technique_id']\n",
        "\n",
        "        # Perform evaluation\n",
        "        print(f'\\nEvaluating {file}')\n",
        "        evaluation(true_labels, predicted_labels)\n",
        "\n",
        "    except KeyError as e:\n",
        "        print(f'Error: Column {e} not found in {file}')\n",
        "    except Exception as e:\n",
        "        print(f'An error occurred while processing {file}: {e}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hd4RNy1N_BWw",
        "outputId": "835f47e1-3d10-4889-a940-3f2154d87c98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluating Nir_Dataset_162_without_techniques.csv\n",
            "Metric    |   Score\n",
            "-------------------\n",
            "Precision |   0.14\n",
            "Recall    |   0.12\n",
            "F1 Score  |   0.13\n",
            "\n",
            "Evaluating Nir_Dataset_162_with_techniques.csv\n",
            "Metric    |   Score\n",
            "-------------------\n",
            "Precision |   0.09\n",
            "Recall    |   0.24\n",
            "F1 Score  |   0.13\n",
            "\n",
            "Evaluating Our_Dataset_300_without_techniques_and_zero_shot.csv\n",
            "Metric    |   Score\n",
            "-------------------\n",
            "Precision |   0.09\n",
            "Recall    |   0.10\n",
            "F1 Score  |   0.09\n",
            "\n",
            "Evaluating Our_Dataset_300_with_techniques_zero_shot.csv\n",
            "Metric    |   Score\n",
            "-------------------\n",
            "Precision |   0.09\n",
            "Recall    |   0.16\n",
            "F1 Score  |   0.12\n",
            "\n",
            "Evaluating Our_Dataset_300_without_techniques_and_one_shot.csv\n",
            "Metric    |   Score\n",
            "-------------------\n",
            "Precision |   0.09\n",
            "Recall    |   0.11\n",
            "F1 Score  |   0.10\n",
            "\n",
            "Evaluating Our_Dataset_300_without_techniques_and_two_shot.csv\n",
            "Metric    |   Score\n",
            "-------------------\n",
            "Precision |   0.07\n",
            "Recall    |   0.07\n",
            "F1 Score  |   0.07\n",
            "\n",
            "Evaluating Our_Dataset_300_with_techniques_two_shot.csv\n",
            "Metric    |   Score\n",
            "-------------------\n",
            "Precision |   0.08\n",
            "Recall    |   0.29\n",
            "F1 Score  |   0.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_metrics(true_labels, predicted_labels):\n",
        "    precision = precision_score(true_labels, predicted_labels, average='macro', zero_division=0)\n",
        "    recall = recall_score(true_labels, predicted_labels, average='macro', zero_division=0)\n",
        "    f1 = f1_score(true_labels, predicted_labels, average='macro', zero_division=0)\n",
        "    return precision, recall, f1\n",
        "\n",
        "results = []\n",
        "\n",
        "for file in file_names:\n",
        "    try:\n",
        "        loadData = pd.read_csv(file)\n",
        "        true_labels = loadData['True_labels']\n",
        "        predicted_labels = loadData['Technique_id']\n",
        "\n",
        "        precision, recall, f1 = evaluate_metrics(true_labels, predicted_labels)\n",
        "\n",
        "        results.append({\n",
        "            'filename': file,\n",
        "            'Precision': f\"{precision:.2f}\",\n",
        "            'Recall': f\"{recall:.2f}\",\n",
        "            'F1 Score': f\"{f1:.2f}\"\n",
        "        })\n",
        "\n",
        "    except KeyError as e:\n",
        "        print(f'Error: Column {e} not found in {file}')\n",
        "    except Exception as e:\n",
        "        print(f'An error occurred while processing {file}: {e}')\n",
        "\n",
        "results_df = pd.DataFrame(results)\n",
        "print(tabulate(results_df, headers='keys', tablefmt='grid'))"
      ],
      "metadata": {
        "id": "Lnbbzjv6BExM"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "VnatnaJWBVxS",
        "ZOeuevpEthmI",
        "kXZc9FsDt6NI",
        "9BUVU20puL_k",
        "U8gJFCcpvinU",
        "RatZWbuyvrKg"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}